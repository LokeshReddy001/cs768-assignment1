{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11646642,"sourceType":"datasetVersion","datasetId":7308499},{"sourceId":11646897,"sourceType":"datasetVersion","datasetId":7308677},{"sourceId":11653341,"sourceType":"datasetVersion","datasetId":7313216},{"sourceId":11662302,"sourceType":"datasetVersion","datasetId":7318953},{"sourceId":11663332,"sourceType":"datasetVersion","datasetId":7319665},{"sourceId":11679308,"sourceType":"datasetVersion","datasetId":7330313},{"sourceId":370142,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":306482,"modelId":326947}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install torch-geometric\n# !pip install rapidfuzz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T10:12:37.321883Z","iopub.execute_input":"2025-05-05T10:12:37.322637Z","iopub.status.idle":"2025-05-05T10:12:46.956278Z","shell.execute_reply.started":"2025-05-05T10:12:37.322611Z","shell.execute_reply":"2025-05-05T10:12:46.955488Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\nCollecting rapidfuzz\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz\nSuccessfully installed rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# import argparse\n# import networkx as nx\n# import numpy as np\n# import matplotlib\n# matplotlib.use('Agg')\n# import matplotlib.pyplot as plt\n\n# import torch\n# import torch.nn.functional as F\n# from torch_geometric.nn import GraphSAGE  # or SAGEConv + custom\n# from torch_geometric.data import Data\n# from torch_geometric.utils import negative_sampling, structured_negative_sampling\n# from torch_geometric.loader import NeighborLoader\n\n# from sentence_transformers import SentenceTransformer\n# from sklearn.model_selection import train_test_split\n\n# import os\n# from tqdm import tqdm\n# import re\n# from rapidfuzz import process, fuzz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T10:12:46.958032Z","iopub.execute_input":"2025-05-05T10:12:46.958315Z","iopub.status.idle":"2025-05-05T10:13:11.939865Z","shell.execute_reply.started":"2025-05-05T10:12:46.958293Z","shell.execute_reply":"2025-05-05T10:13:11.939084Z"}},"outputs":[{"name":"stderr","text":"2025-05-05 10:12:58.041660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746439978.248440      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746439978.308625      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# # GRAPH BUILDER CODE\n# def extract_brace_content(text, start_idx):\n#     \"\"\"Extract content inside balanced braces starting from the given index.\"\"\"\n#     assert text[start_idx] == '{'\n#     depth = 0\n#     i = start_idx\n#     while i < len(text):\n#         if text[i] == '{':\n#             depth += 1\n#         elif text[i] == '}':\n#             depth -= 1\n#             if depth == 0:\n#                 return text[start_idx+1:i], i + 1\n#         i += 1\n#     return \"\", i\n\n# def parse_bbl(bbl_path='t.bbl'):\n#     \"\"\"Extract reference titles from .bbl file supporting multiple formats.\"\"\"\n#     try:\n#         with open(bbl_path, 'r', encoding='utf8') as f:\n#             text = f.read()\n#     except UnicodeDecodeError:\n#         with open(bbl_path, 'r', encoding='latin-1') as f:\n#             text = f.read()\n\n#     titles = []\n\n#     # 1. BibLaTeX \\entry{...} blocks\n#     entry_blocks = re.findall(r'\\\\entry\\{.*?\\}\\{.*?\\}\\{.*?\\}(.*?)\\\\endentry', text, flags=re.DOTALL)\n#     for block in entry_blocks:\n#         idx = block.find(r'\\field{title}')\n#         if idx != -1:\n#             brace_start = block.find('{', idx + len(r'\\field{title}'))\n#             if brace_start != -1:\n#                 raw_title, _ = extract_brace_content(block, brace_start)\n#                 title = clean_title(raw_title)\n#                 titles.append(title)\n\n#     # 2. \\bib{key}{type}{...} blocks\n#     bib_blocks = re.findall(r'\\\\bib\\{.*?\\}\\{.*?\\}\\{(.*?)\\n\\}', text, flags=re.DOTALL)\n#     for block in bib_blocks:\n#         match = re.search(r'title\\s*=\\s*\\{(.*?)\\}', block, flags=re.DOTALL)\n#         if match:\n#             title = clean_title(match.group(1))\n#             titles.append(title)\n\n#     # 3. \\bibitem blocks\n#     bibitems = re.split(r\"\\\\bibitem(?:\\[[^\\]]*\\]){0,3}\\{.*?\\}\", text)[1:]\n#     for block in bibitems:\n#         title = None\n\n#         # (a) \\showarticletitle{...}\n#         match = re.search(r'\\\\showarticletitle\\s*\\{(.*?)\\}', block, flags=re.DOTALL)\n#         if match:\n#             title = clean_title(match.group(1))\n#         else:\n#             # (b) \\newblock ...\n#             parts = re.split(r\"\\\\newblock\", block)\n#             if len(parts) >= 2:\n#                 title = clean_title(parts[1])\n#             else:\n#                 # (c) ``...'' quoted title\n#                 quote_match = re.search(r\"``(.*?)''\", block, flags=re.DOTALL)\n#                 if quote_match:\n#                     title = clean_title(quote_match.group(1))\n#                 else:\n#                     # (d) : {Title}\n#                     colon_title = re.search(r':[ \\n]*\\{(.*?)\\}', block, flags=re.DOTALL)\n#                     if colon_title:\n#                         title = clean_title(colon_title.group(1))\n\n#         if title:\n#             titles.append(title)\n\n#     # 4. Handle cases like \\url{...}\n#     urls = re.findall(r'\\\\url\\{(.*?)\\}', text)\n#     for url in urls:\n#         # Optionally, save URLs if needed\n#         pass\n#     # if len(titles)==0:\n#     #     print(bbl_path)\n#     return titles\n\n# def parse_bib(bib_file_path):\n#     try:\n#         with open(bib_file_path, 'r', encoding='utf8') as f:\n#             bib_string = f.read()\n#     except UnicodeDecodeError:\n#         with open(bib_file_path, 'r', encoding='latin-1') as f:\n#             bib_string = f.read()\n\n#     # pattern = r'title\\s*=\\s*(?:\\{(.*?)\\}|\"(.*?)\")'\n#     # matches = re.findall(pattern, bib_string, flags=re.IGNORECASE | re.DOTALL)\n\n#     # cleaned_titles = []\n#     # for brace_match, quote_match in matches:\n#     #     title = brace_match if brace_match else quote_match\n\n#     #     title = title.strip()\n#     #     title = re.sub(r\"^[\\{\\}]+|[\\{\\}]+$\", \"\", title)\n#     #     cleaned_titles.append(title.strip())\n\n#     # return cleaned_titles\n#     pattern = r'(?:^|\\n|,\\s*)title\\s*=\\s*(?:\\{|\")(.*?)(?:\\}|\")'\n#     matches = re.findall(pattern, bib_string, flags=re.IGNORECASE | re.DOTALL)\n\n#     cleaned_titles = []\n#     for title in matches:\n#         # The regex now directly captures the content within braces/quotes in group 1\n#         title = title.strip()\n#         # Apply the brace remover just in case of nested braces (less common now)\n#         # and final strip.\n#         cleaned_titles.append(re.sub(r\"^[\\{\\}]+|[\\{\\}]+$\", \"\", title).strip())\n\n#     return cleaned_titles\n\n# def clean_title(raw):\n#     \"\"\"Cleans LaTeX formatting from title string.\"\"\"\n#     raw = raw.replace('\\n', ' ')\n#     raw = re.sub(r'\\s+', ' ', raw)\n#     raw = re.sub(r'\\{\\\\[a-zA-Z]+\\s+(.*?)\\}', r'\\1', raw)   # {\\em foo} → foo\n#     raw = re.sub(r'\\\\[a-zA-Z]+\\s*', '', raw)               # \\em, \\url, etc\n#     raw = re.sub(r'[{}]', '', raw)                         # remove braces\n#     return raw.strip(' .')\n\n\n\n# def build_title_map(data_dir):\n#     \"\"\"Map paper_id -> paper title from title.txt.\"\"\"\n#     title_map = {}\n#     cnt = 0\n#     print(\"toal = \", len(os.listdir(data_dir)))\n#     for paper in os.listdir(data_dir):\n#         cnt += 1\n#         if cnt %1000 == 0:\n#             print(cnt)\n#         pap_dir = os.path.join(data_dir, paper)\n#         tfile = os.path.join(pap_dir, 'title.txt')\n#         if os.path.isdir(pap_dir) and os.path.isfile(tfile):\n#             with open(tfile, 'r', encoding='utf8') as f:\n#                 title_map[paper] = f.read().strip()\n#     return title_map\n\n# def build_references(data_dir):\n#     \"\"\"Map paper_id -> list of reference titles.\"\"\"\n#     refs = {}\n#     for paper in os.listdir(data_dir):\n#         pap_dir = os.path.join(data_dir, paper)\n#         if not os.path.isdir(pap_dir):\n#             continue\n#         # find .bbl\n#         found_bbl = False\n#         for fname in os.listdir(pap_dir):\n#             if fname.endswith('.bbl'):\n#                 found_bbl = True\n#                 bbl_path = os.path.join(pap_dir, fname)\n#                 refs[paper] = parse_bbl(bbl_path)\n#                 break\n#         if not found_bbl:\n#             for fname in os.listdir(pap_dir):\n#                 if fname.endswith('.bib'):\n#                     bib_path = os.path.join(pap_dir, fname)\n#                     refs[paper] = parse_bib(bib_path)\n#                     break\n#     return refs\n\n# def match_refs_to_papers(refs, title_map, threshold=80):\n#     \"\"\"Fuzzy match reference titles to known paper titles.\"\"\"\n#     graph = nx.DiGraph()\n#     # add nodes\n#     for pid in title_map:\n#         graph.add_node(pid)\n#     titles = list(title_map.values())\n#     pid_by_title = {v: k for k, v in title_map.items()}\n\n#     for src, rlist in tqdm(refs.items(), desc='Matching refs'):\n#         for ref in rlist:\n#             match, score, _ = process.extractOne(ref, titles, scorer=fuzz.token_set_ratio)\n#             if score >= threshold:\n#                 tgt = pid_by_title.get(match)\n#                 if tgt:\n#                     graph.add_edge(src, tgt)\n#     return graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T10:13:11.941299Z","iopub.execute_input":"2025-05-05T10:13:11.942084Z","iopub.status.idle":"2025-05-05T10:13:11.959218Z","shell.execute_reply.started":"2025-05-05T10:13:11.942060Z","shell.execute_reply":"2025-05-05T10:13:11.958516Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# # INVOCATION OF GRAPH BUILDER\n# def generate_graphml():  \n#     data_dir = \"/kaggle/input/papers/dataset_papers\"\n#     out = \"citation_graph.graphml\"\n    \n#     title_map = build_title_map(data_dir)\n#     print(\"1\")\n#     refs = build_references(data_dir)\n#     print(\"2\")\n#     G = match_refs_to_papers(refs, title_map)\n#     print(\"3\")\n#     nx.write_graphml(G, out)\n#     print(G.number_of_edges(), G.number_of_nodes())\n#     # print(f\"Graph written to {args.out} with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T10:13:11.960130Z","iopub.execute_input":"2025-05-05T10:13:11.960441Z","iopub.status.idle":"2025-05-05T10:13:12.061901Z","shell.execute_reply.started":"2025-05-05T10:13:11.960415Z","shell.execute_reply":"2025-05-05T10:13:12.061183Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# generate_graphml()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T10:13:15.764655Z","iopub.execute_input":"2025-05-05T10:13:15.765343Z","iopub.status.idle":"2025-05-05T11:22:12.213450Z","shell.execute_reply.started":"2025-05-05T10:13:15.765318Z","shell.execute_reply":"2025-05-05T11:22:12.212631Z"}},"outputs":[{"name":"stdout","text":"toal =  6545\n1000\n2000\n3000\n4000\n5000\n6000\n1\n2\n","output_type":"stream"},{"name":"stderr","text":"Matching refs: 100%|██████████| 6545/6545 [1:05:45<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"3\n28686 6545\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n# # 1. Prepare text embeddings\n# sbert = SentenceTransformer('all-MiniLM-L6-v2')\n\n# class LinkPredictor(torch.nn.Module):\n#     def __init__(self, in_dim=384, hidden=128, num_layers=2):\n#         super().__init__()\n#         # Initialize GraphSAGE with specified number of layers\n#         self.sage = GraphSAGE(in_channels=in_dim, hidden_channels=hidden, num_layers=num_layers)\n#         # self.lin = torch.nn.Linear(hidden*2, 1)\n\n#     def forward(self, x, edge_index, pos_edge_label_index, neg_edge_label_index):\n#         h = self.sage(x, edge_index)\n#         # # positive\n#         # pos_h = torch.cat([h[pos_edge_label_index[0]], h[pos_edge_label_index[1]]], dim=1)\n#         # neg_h = torch.cat([h[neg_edge_label_index[0]], h[neg_edge_label_index[1]]], dim=1)\n#         # pos_score = self.lin(pos_h).view(-1)\n#         # neg_score = self.lin(neg_h).view(-1)\n#         # return pos_score, neg_score\n#             # Dot product for positive edges\n#         pos_score = (h[pos_edge_label_index[0]] * h[pos_edge_label_index[1]]).sum(dim=1)\n        \n#         # Dot product for negative edges\n#         neg_score = (h[neg_edge_label_index[0]] * h[neg_edge_label_index[1]]).sum(dim=1)\n        \n#         return pos_score, neg_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T11:22:12.214830Z","iopub.execute_input":"2025-05-05T11:22:12.215489Z","iopub.status.idle":"2025-05-05T11:22:30.064787Z","shell.execute_reply.started":"2025-05-05T11:22:12.215467Z","shell.execute_reply":"2025-05-05T11:22:30.064212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8b2c4e2718e40e28b29b7a84f3f18be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c409bf4de9e4e3b88f461020262ca96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a29b079bebd4bff992fefdb25911f3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f506b54ce7804a1dbb7170bb40878684"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1bf147fefc4905bd8658cce36887c1"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5554a70e55fc4d8db640b48ac138dcfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"635397062d6a47f6b70a95897312117f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b51a9c461ff04a9799c9e5d87aac3a72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac5154be2f941a0afd0c5a667250b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ee6893a7dc1453fa1e226b71238685a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe740b0fd9c4817aabdd46ff4191469"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# def load_graph1(graph_path):\n#     Gnx = nx.read_graphml(graph_path)\n#     mapping = {nid: i for i, nid in enumerate(Gnx.nodes())}\n#     # build edge_index\n#     edges = [[mapping[u], mapping[v]] for u, v in Gnx.edges()]\n#     edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n#     return edge_index, mapping\n\n\n# def load_text_embeddings(data_dir, mapping, device):\n#     sbert = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n#     x = torch.zeros((len(mapping), 384), dtype=torch.float, device=device)\n#     for nid, idx in tqdm(mapping.items(), desc='Embedding texts'):\n#         txt = ''\n#         for fname in ('title.txt', 'abstract.txt'):\n#             path = os.path.join(data_dir, nid, fname)\n#             if os.path.isfile(path):\n#                 txt += open(path, 'r', encoding='utf8').read().strip() + ' '\n#         if txt:\n#             emb = sbert.encode(txt, convert_to_tensor=True, show_progress_bar=False)\n#             x[idx] = emb\n#     x = F.normalize(x, p=2, dim=1)\n#     return x\n\n\n# def train(args, x):\n#     device = torch.device(args.device)\n#     print(device)\n#     edge_index, mapping = load_graph1(args.graph)\n#     edge_index = edge_index.to(device)\n\n#     # split pos edges into train/val\n#     num_edges = edge_index.size(1)\n#     perm = torch.randperm(num_edges)\n#     val_cnt = int(0.1 * num_edges)\n#     val_idx = perm[:val_cnt]\n#     train_idx = perm[val_cnt:]\n#     pos_train = edge_index[:, train_idx]\n#     pos_val = edge_index[:, val_idx]\n\n#     model = LinkPredictor(in_dim=x.size(1), hidden=128, num_layers=2).to(device)\n#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n\n#     for epoch in range(1, args.epochs+1):\n#         print(epoch)\n#         model.train()\n#         optimizer.zero_grad()\n#         neg_train = negative_sampling(edge_index, num_neg_samples=pos_train.size(1), method='sparse')\n#         pos_out, neg_out = model(x, edge_index, pos_train, neg_train)\n#         loss = (\n#             F.binary_cross_entropy_with_logits(pos_out, torch.ones_like(pos_out)) +\n#             F.binary_cross_entropy_with_logits(neg_out, torch.zeros_like(neg_out))\n#         ) / 2\n#         loss.backward()\n#         optimizer.step()\n\n#         model.eval()\n#         with torch.no_grad():\n#             neg_val = negative_sampling(edge_index, num_neg_samples=pos_val.size(1), method='sparse')\n#             pos_v, neg_v = model(x, edge_index, pos_val, neg_val)\n#             val_loss = (\n#                 F.binary_cross_entropy_with_logits(pos_v, torch.ones_like(pos_v)) +\n#                 F.binary_cross_entropy_with_logits(neg_v, torch.zeros_like(neg_v))\n#             ) / 2\n#         print(f'Epoch {epoch}/{args.epochs} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}')\n\n#     # os.makedirs(os.path.dirname(args.out_model), exist_ok=True)\n#     # torch.save(model.state_dict(), args.out_model)\n#     # save final node embeddings\n#     emb = model.sage(x, edge_index).cpu()\n#     print(emb.shape)\n#     with torch.no_grad():\n#         per_node_std = emb.std(dim=1)\n#         per_node_mean = emb.mean(dim=1)\n#         print(per_node_std[:10])\n#         print(per_node_mean[:10])\n#         print(f\"Mean of per-node std: {per_node_std.mean().item():.6f}\")\n#         print(f\"Mean of per-node mean: {per_node_mean.mean().item():.6f}\")\n\n\n#     # torch.save(emb, os.path.join(os.path.dirname(args.out_model), 'node_embeddings.pt'))\n#     print('Training complete. Model and embeddings saved.')\n#     torch.save(model, '/kaggle/working/model.pth')\n#     return model.state_dict(), emb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T06:04:15.698443Z","iopub.execute_input":"2025-05-05T06:04:15.699017Z","iopub.status.idle":"2025-05-05T06:04:15.711158Z","shell.execute_reply.started":"2025-05-05T06:04:15.698994Z","shell.execute_reply":"2025-05-05T06:04:15.710586Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# class Config:\n#     graph = '/kaggle/input/final-graph/final_citations_graph.graphml'\n#     # graph = '/kaggle/working/citation_graph.graphml'\n#     data_dir = '/kaggle/input/papers/dataset_papers'          # Replace with actual path\n#     epochs = 200\n#     lr = 2e-3\n#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n#     out_model = 'linkpred.pt'  # You can save to /kaggle/working/\n\n# def wrap_train(text_emb_path = '/kaggle/input/text-embeddings/text_embeddings.pt'):\n#     args = Config()\n    \n#     _, mapping = load_graph1(args.graph)\n#     device = torch.device(args.device)\n    \n#     # x = load_text_embeddings(args.data_dir, mapping, device)\n#     # torch.save(x.cpu(), text_emb_path)\n\n#     x = torch.load(text_emb_path, map_location=device)\n    \n#     state_dict, emb = train(args, x)\n#     torch.save(state_dict, '/kaggle/working/'+args.out_model)\n#     torch.save(emb, '/kaggle/working/'+'node_embeddings.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T06:06:02.162959Z","iopub.execute_input":"2025-05-05T06:06:02.163604Z","iopub.status.idle":"2025-05-05T06:06:02.168608Z","shell.execute_reply.started":"2025-05-05T06:06:02.163579Z","shell.execute_reply":"2025-05-05T06:06:02.167941Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# wrap_train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T06:06:03.001692Z","iopub.execute_input":"2025-05-05T06:06:03.002245Z","iopub.status.idle":"2025-05-05T06:06:10.995993Z","shell.execute_reply.started":"2025-05-05T06:06:03.002219Z","shell.execute_reply":"2025-05-05T06:06:10.995278Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1672017970.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  x = torch.load(text_emb_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"cuda\n1\nEpoch 1/200 | Train Loss: 0.7088 | Val Loss: 0.6962\n2\nEpoch 2/200 | Train Loss: 0.6962 | Val Loss: 0.6839\n3\nEpoch 3/200 | Train Loss: 0.6837 | Val Loss: 0.6741\n4\nEpoch 4/200 | Train Loss: 0.6708 | Val Loss: 0.6785\n5\nEpoch 5/200 | Train Loss: 0.6748 | Val Loss: 0.6600\n6\nEpoch 6/200 | Train Loss: 0.6575 | Val Loss: 0.6553\n7\nEpoch 7/200 | Train Loss: 0.6567 | Val Loss: 0.6504\n8\nEpoch 8/200 | Train Loss: 0.6517 | Val Loss: 0.6424\n9\nEpoch 9/200 | Train Loss: 0.6431 | Val Loss: 0.6348\n10\nEpoch 10/200 | Train Loss: 0.6377 | Val Loss: 0.6264\n11\nEpoch 11/200 | Train Loss: 0.6281 | Val Loss: 0.6242\n12\nEpoch 12/200 | Train Loss: 0.6180 | Val Loss: 0.6035\n13\nEpoch 13/200 | Train Loss: 0.6060 | Val Loss: 0.5977\n14\nEpoch 14/200 | Train Loss: 0.6004 | Val Loss: 0.5893\n15\nEpoch 15/200 | Train Loss: 0.5948 | Val Loss: 0.5872\n16\nEpoch 16/200 | Train Loss: 0.5936 | Val Loss: 0.5929\n17\nEpoch 17/200 | Train Loss: 0.5890 | Val Loss: 0.5821\n18\nEpoch 18/200 | Train Loss: 0.5853 | Val Loss: 0.5815\n19\nEpoch 19/200 | Train Loss: 0.5816 | Val Loss: 0.5624\n20\nEpoch 20/200 | Train Loss: 0.5746 | Val Loss: 0.5704\n21\nEpoch 21/200 | Train Loss: 0.5729 | Val Loss: 0.5631\n22\nEpoch 22/200 | Train Loss: 0.5721 | Val Loss: 0.5670\n23\nEpoch 23/200 | Train Loss: 0.5669 | Val Loss: 0.5693\n24\nEpoch 24/200 | Train Loss: 0.5646 | Val Loss: 0.5577\n25\nEpoch 25/200 | Train Loss: 0.5627 | Val Loss: 0.5531\n26\nEpoch 26/200 | Train Loss: 0.5585 | Val Loss: 0.5586\n27\nEpoch 27/200 | Train Loss: 0.5504 | Val Loss: 0.5522\n28\nEpoch 28/200 | Train Loss: 0.5509 | Val Loss: 0.5453\n29\nEpoch 29/200 | Train Loss: 0.5444 | Val Loss: 0.5294\n30\nEpoch 30/200 | Train Loss: 0.5418 | Val Loss: 0.5367\n31\nEpoch 31/200 | Train Loss: 0.5434 | Val Loss: 0.5451\n32\nEpoch 32/200 | Train Loss: 0.5427 | Val Loss: 0.5339\n33\nEpoch 33/200 | Train Loss: 0.5398 | Val Loss: 0.5462\n34\nEpoch 34/200 | Train Loss: 0.5367 | Val Loss: 0.5380\n35\nEpoch 35/200 | Train Loss: 0.5387 | Val Loss: 0.5284\n36\nEpoch 36/200 | Train Loss: 0.5348 | Val Loss: 0.5299\n37\nEpoch 37/200 | Train Loss: 0.5313 | Val Loss: 0.5218\n38\nEpoch 38/200 | Train Loss: 0.5291 | Val Loss: 0.5237\n39\nEpoch 39/200 | Train Loss: 0.5252 | Val Loss: 0.5186\n40\nEpoch 40/200 | Train Loss: 0.5239 | Val Loss: 0.5225\n41\nEpoch 41/200 | Train Loss: 0.5217 | Val Loss: 0.5245\n42\nEpoch 42/200 | Train Loss: 0.5201 | Val Loss: 0.5166\n43\nEpoch 43/200 | Train Loss: 0.5234 | Val Loss: 0.5169\n44\nEpoch 44/200 | Train Loss: 0.5197 | Val Loss: 0.5098\n45\nEpoch 45/200 | Train Loss: 0.5176 | Val Loss: 0.5143\n46\nEpoch 46/200 | Train Loss: 0.5179 | Val Loss: 0.5161\n47\nEpoch 47/200 | Train Loss: 0.5177 | Val Loss: 0.5056\n48\nEpoch 48/200 | Train Loss: 0.5160 | Val Loss: 0.5046\n49\nEpoch 49/200 | Train Loss: 0.5174 | Val Loss: 0.5101\n50\nEpoch 50/200 | Train Loss: 0.5149 | Val Loss: 0.5058\n51\nEpoch 51/200 | Train Loss: 0.5154 | Val Loss: 0.5104\n52\nEpoch 52/200 | Train Loss: 0.5142 | Val Loss: 0.5016\n53\nEpoch 53/200 | Train Loss: 0.5099 | Val Loss: 0.5041\n54\nEpoch 54/200 | Train Loss: 0.5095 | Val Loss: 0.5115\n55\nEpoch 55/200 | Train Loss: 0.5088 | Val Loss: 0.5051\n56\nEpoch 56/200 | Train Loss: 0.5088 | Val Loss: 0.5122\n57\nEpoch 57/200 | Train Loss: 0.5075 | Val Loss: 0.5007\n58\nEpoch 58/200 | Train Loss: 0.5092 | Val Loss: 0.5084\n59\nEpoch 59/200 | Train Loss: 0.5050 | Val Loss: 0.5058\n60\nEpoch 60/200 | Train Loss: 0.5090 | Val Loss: 0.5141\n61\nEpoch 61/200 | Train Loss: 0.5039 | Val Loss: 0.4986\n62\nEpoch 62/200 | Train Loss: 0.5078 | Val Loss: 0.5112\n63\nEpoch 63/200 | Train Loss: 0.5028 | Val Loss: 0.4964\n64\nEpoch 64/200 | Train Loss: 0.5049 | Val Loss: 0.4999\n65\nEpoch 65/200 | Train Loss: 0.5034 | Val Loss: 0.5029\n66\nEpoch 66/200 | Train Loss: 0.5028 | Val Loss: 0.5036\n67\nEpoch 67/200 | Train Loss: 0.5000 | Val Loss: 0.5013\n68\nEpoch 68/200 | Train Loss: 0.5010 | Val Loss: 0.4961\n69\nEpoch 69/200 | Train Loss: 0.5018 | Val Loss: 0.5047\n70\nEpoch 70/200 | Train Loss: 0.5037 | Val Loss: 0.4996\n71\nEpoch 71/200 | Train Loss: 0.5018 | Val Loss: 0.5009\n72\nEpoch 72/200 | Train Loss: 0.4988 | Val Loss: 0.5019\n73\nEpoch 73/200 | Train Loss: 0.5007 | Val Loss: 0.4937\n74\nEpoch 74/200 | Train Loss: 0.4975 | Val Loss: 0.5008\n75\nEpoch 75/200 | Train Loss: 0.4994 | Val Loss: 0.4976\n76\nEpoch 76/200 | Train Loss: 0.4980 | Val Loss: 0.5057\n77\nEpoch 77/200 | Train Loss: 0.5000 | Val Loss: 0.4980\n78\nEpoch 78/200 | Train Loss: 0.4985 | Val Loss: 0.5034\n79\nEpoch 79/200 | Train Loss: 0.4985 | Val Loss: 0.4874\n80\nEpoch 80/200 | Train Loss: 0.4965 | Val Loss: 0.4952\n81\nEpoch 81/200 | Train Loss: 0.4951 | Val Loss: 0.4912\n82\nEpoch 82/200 | Train Loss: 0.4952 | Val Loss: 0.4970\n83\nEpoch 83/200 | Train Loss: 0.4952 | Val Loss: 0.4954\n84\nEpoch 84/200 | Train Loss: 0.4945 | Val Loss: 0.4906\n85\nEpoch 85/200 | Train Loss: 0.4965 | Val Loss: 0.4942\n86\nEpoch 86/200 | Train Loss: 0.4941 | Val Loss: 0.4925\n87\nEpoch 87/200 | Train Loss: 0.4932 | Val Loss: 0.4988\n88\nEpoch 88/200 | Train Loss: 0.4921 | Val Loss: 0.4908\n89\nEpoch 89/200 | Train Loss: 0.4895 | Val Loss: 0.4989\n90\nEpoch 90/200 | Train Loss: 0.4903 | Val Loss: 0.4906\n91\nEpoch 91/200 | Train Loss: 0.4912 | Val Loss: 0.4989\n92\nEpoch 92/200 | Train Loss: 0.4908 | Val Loss: 0.4963\n93\nEpoch 93/200 | Train Loss: 0.4894 | Val Loss: 0.4859\n94\nEpoch 94/200 | Train Loss: 0.4918 | Val Loss: 0.4912\n95\nEpoch 95/200 | Train Loss: 0.4897 | Val Loss: 0.4930\n96\nEpoch 96/200 | Train Loss: 0.4903 | Val Loss: 0.4896\n97\nEpoch 97/200 | Train Loss: 0.4890 | Val Loss: 0.4899\n98\nEpoch 98/200 | Train Loss: 0.4881 | Val Loss: 0.4844\n99\nEpoch 99/200 | Train Loss: 0.4880 | Val Loss: 0.4995\n100\nEpoch 100/200 | Train Loss: 0.4881 | Val Loss: 0.4893\n101\nEpoch 101/200 | Train Loss: 0.4847 | Val Loss: 0.4890\n102\nEpoch 102/200 | Train Loss: 0.4866 | Val Loss: 0.4868\n103\nEpoch 103/200 | Train Loss: 0.4857 | Val Loss: 0.4872\n104\nEpoch 104/200 | Train Loss: 0.4856 | Val Loss: 0.4871\n105\nEpoch 105/200 | Train Loss: 0.4857 | Val Loss: 0.4814\n106\nEpoch 106/200 | Train Loss: 0.4851 | Val Loss: 0.4787\n107\nEpoch 107/200 | Train Loss: 0.4856 | Val Loss: 0.4856\n108\nEpoch 108/200 | Train Loss: 0.4847 | Val Loss: 0.4856\n109\nEpoch 109/200 | Train Loss: 0.4818 | Val Loss: 0.4854\n110\nEpoch 110/200 | Train Loss: 0.4819 | Val Loss: 0.4810\n111\nEpoch 111/200 | Train Loss: 0.4835 | Val Loss: 0.4827\n112\nEpoch 112/200 | Train Loss: 0.4835 | Val Loss: 0.4892\n113\nEpoch 113/200 | Train Loss: 0.4811 | Val Loss: 0.4847\n114\nEpoch 114/200 | Train Loss: 0.4797 | Val Loss: 0.4798\n115\nEpoch 115/200 | Train Loss: 0.4817 | Val Loss: 0.4869\n116\nEpoch 116/200 | Train Loss: 0.4784 | Val Loss: 0.4893\n117\nEpoch 117/200 | Train Loss: 0.4771 | Val Loss: 0.4790\n118\nEpoch 118/200 | Train Loss: 0.4815 | Val Loss: 0.4844\n119\nEpoch 119/200 | Train Loss: 0.4794 | Val Loss: 0.4875\n120\nEpoch 120/200 | Train Loss: 0.4803 | Val Loss: 0.4819\n121\nEpoch 121/200 | Train Loss: 0.4804 | Val Loss: 0.4813\n122\nEpoch 122/200 | Train Loss: 0.4802 | Val Loss: 0.4810\n123\nEpoch 123/200 | Train Loss: 0.4773 | Val Loss: 0.4816\n124\nEpoch 124/200 | Train Loss: 0.4793 | Val Loss: 0.4827\n125\nEpoch 125/200 | Train Loss: 0.4763 | Val Loss: 0.4804\n126\nEpoch 126/200 | Train Loss: 0.4801 | Val Loss: 0.4765\n127\nEpoch 127/200 | Train Loss: 0.4759 | Val Loss: 0.4806\n128\nEpoch 128/200 | Train Loss: 0.4784 | Val Loss: 0.4812\n129\nEpoch 129/200 | Train Loss: 0.4758 | Val Loss: 0.4786\n130\nEpoch 130/200 | Train Loss: 0.4781 | Val Loss: 0.4813\n131\nEpoch 131/200 | Train Loss: 0.4762 | Val Loss: 0.4742\n132\nEpoch 132/200 | Train Loss: 0.4755 | Val Loss: 0.4836\n133\nEpoch 133/200 | Train Loss: 0.4760 | Val Loss: 0.4777\n134\nEpoch 134/200 | Train Loss: 0.4759 | Val Loss: 0.4794\n135\nEpoch 135/200 | Train Loss: 0.4745 | Val Loss: 0.4785\n136\nEpoch 136/200 | Train Loss: 0.4765 | Val Loss: 0.4768\n137\nEpoch 137/200 | Train Loss: 0.4737 | Val Loss: 0.4790\n138\nEpoch 138/200 | Train Loss: 0.4735 | Val Loss: 0.4853\n139\nEpoch 139/200 | Train Loss: 0.4732 | Val Loss: 0.4740\n140\nEpoch 140/200 | Train Loss: 0.4746 | Val Loss: 0.4749\n141\nEpoch 141/200 | Train Loss: 0.4741 | Val Loss: 0.4830\n142\nEpoch 142/200 | Train Loss: 0.4719 | Val Loss: 0.4772\n143\nEpoch 143/200 | Train Loss: 0.4731 | Val Loss: 0.4782\n144\nEpoch 144/200 | Train Loss: 0.4760 | Val Loss: 0.4867\n145\nEpoch 145/200 | Train Loss: 0.4728 | Val Loss: 0.4764\n146\nEpoch 146/200 | Train Loss: 0.4730 | Val Loss: 0.4781\n147\nEpoch 147/200 | Train Loss: 0.4731 | Val Loss: 0.4795\n148\nEpoch 148/200 | Train Loss: 0.4720 | Val Loss: 0.4767\n149\nEpoch 149/200 | Train Loss: 0.4713 | Val Loss: 0.4696\n150\nEpoch 150/200 | Train Loss: 0.4713 | Val Loss: 0.4725\n151\nEpoch 151/200 | Train Loss: 0.4731 | Val Loss: 0.4790\n152\nEpoch 152/200 | Train Loss: 0.4714 | Val Loss: 0.4827\n153\nEpoch 153/200 | Train Loss: 0.4689 | Val Loss: 0.4784\n154\nEpoch 154/200 | Train Loss: 0.4694 | Val Loss: 0.4703\n155\nEpoch 155/200 | Train Loss: 0.4697 | Val Loss: 0.4744\n156\nEpoch 156/200 | Train Loss: 0.4715 | Val Loss: 0.4749\n157\nEpoch 157/200 | Train Loss: 0.4686 | Val Loss: 0.4756\n158\nEpoch 158/200 | Train Loss: 0.4698 | Val Loss: 0.4788\n159\nEpoch 159/200 | Train Loss: 0.4672 | Val Loss: 0.4684\n160\nEpoch 160/200 | Train Loss: 0.4682 | Val Loss: 0.4740\n161\nEpoch 161/200 | Train Loss: 0.4682 | Val Loss: 0.4808\n162\nEpoch 162/200 | Train Loss: 0.4663 | Val Loss: 0.4793\n163\nEpoch 163/200 | Train Loss: 0.4699 | Val Loss: 0.4749\n164\nEpoch 164/200 | Train Loss: 0.4646 | Val Loss: 0.4742\n165\nEpoch 165/200 | Train Loss: 0.4672 | Val Loss: 0.4746\n166\nEpoch 166/200 | Train Loss: 0.4653 | Val Loss: 0.4832\n167\nEpoch 167/200 | Train Loss: 0.4657 | Val Loss: 0.4719\n168\nEpoch 168/200 | Train Loss: 0.4652 | Val Loss: 0.4767\n169\nEpoch 169/200 | Train Loss: 0.4658 | Val Loss: 0.4661\n170\nEpoch 170/200 | Train Loss: 0.4652 | Val Loss: 0.4648\n171\nEpoch 171/200 | Train Loss: 0.4655 | Val Loss: 0.4708\n172\nEpoch 172/200 | Train Loss: 0.4638 | Val Loss: 0.4683\n173\nEpoch 173/200 | Train Loss: 0.4644 | Val Loss: 0.4759\n174\nEpoch 174/200 | Train Loss: 0.4648 | Val Loss: 0.4757\n175\nEpoch 175/200 | Train Loss: 0.4650 | Val Loss: 0.4805\n176\nEpoch 176/200 | Train Loss: 0.4631 | Val Loss: 0.4754\n177\nEpoch 177/200 | Train Loss: 0.4662 | Val Loss: 0.4702\n178\nEpoch 178/200 | Train Loss: 0.4623 | Val Loss: 0.4661\n179\nEpoch 179/200 | Train Loss: 0.4649 | Val Loss: 0.4733\n180\nEpoch 180/200 | Train Loss: 0.4644 | Val Loss: 0.4698\n181\nEpoch 181/200 | Train Loss: 0.4626 | Val Loss: 0.4717\n182\nEpoch 182/200 | Train Loss: 0.4636 | Val Loss: 0.4717\n183\nEpoch 183/200 | Train Loss: 0.4619 | Val Loss: 0.4696\n184\nEpoch 184/200 | Train Loss: 0.4629 | Val Loss: 0.4764\n185\nEpoch 185/200 | Train Loss: 0.4609 | Val Loss: 0.4754\n186\nEpoch 186/200 | Train Loss: 0.4617 | Val Loss: 0.4709\n187\nEpoch 187/200 | Train Loss: 0.4617 | Val Loss: 0.4714\n188\nEpoch 188/200 | Train Loss: 0.4622 | Val Loss: 0.4735\n189\nEpoch 189/200 | Train Loss: 0.4639 | Val Loss: 0.4698\n190\nEpoch 190/200 | Train Loss: 0.4633 | Val Loss: 0.4617\n191\nEpoch 191/200 | Train Loss: 0.4614 | Val Loss: 0.4714\n192\nEpoch 192/200 | Train Loss: 0.4637 | Val Loss: 0.4702\n193\nEpoch 193/200 | Train Loss: 0.4623 | Val Loss: 0.4678\n194\nEpoch 194/200 | Train Loss: 0.4608 | Val Loss: 0.4709\n195\nEpoch 195/200 | Train Loss: 0.4596 | Val Loss: 0.4782\n196\nEpoch 196/200 | Train Loss: 0.4621 | Val Loss: 0.4702\n197\nEpoch 197/200 | Train Loss: 0.4611 | Val Loss: 0.4630\n198\nEpoch 198/200 | Train Loss: 0.4594 | Val Loss: 0.4725\n199\nEpoch 199/200 | Train Loss: 0.4553 | Val Loss: 0.4718\n200\nEpoch 200/200 | Train Loss: 0.4608 | Val Loss: 0.4709\ntorch.Size([6545, 128])\ntensor([0.1277, 0.0892, 0.1548, 0.1251, 0.0982, 0.1613, 0.1775, 0.2129, 0.1821,\n        0.1396])\ntensor([ 0.0044,  0.0080, -0.0064, -0.0057, -0.0107,  0.0231,  0.0107,  0.0041,\n         0.0021,  0.0087])\nMean of per-node std: 0.150603\nMean of per-node mean: 0.001033\nTraining complete. Model and embeddings saved.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# def load_graph2(graph_path):\n#     G = nx.read_graphml(graph_path)\n#     mapping = {nid: i for i, nid in enumerate(G.nodes())}\n#     inv_map = {i: nid for nid, i in mapping.items()}\n#     return G, mapping, inv_map\n\n# # ====== SET YOUR FILE PATHS HERE ======\n# graph_path = '/kaggle/input/final-graph/final_citations_graph.graphml'\n# # emb_path = '/kaggle/input/embeddings/node_embeddings.pt'\n# emb_path = '/kaggle/working/node_embeddings.pt'\n# # model_path = '/kaggle/input/linkpred/pytorch/default/1/linkpred.pt'\n# model_path = '/kaggle/working/linkpred.pt'\n# k = 5\n# # ====== LOAD DATA ======\n# G, mapping, inv_map = load_graph2(graph_path)\n# emb = torch.load(emb_path)\n# # state = torch.load(model_path, map_location='cpu')\n# # lin_weight = state['lin.weight']\n# # lin_bias = state['lin.bias']\n\n# # ====== INFERENCE LOOP ======\n# test_nodes = [nid for nid in G.nodes() if G.out_degree(nid) > 0]\n\n# print(len(test_nodes))\n# cnt = 0\n# for nid in test_nodes:\n#     # u = mapping[nid]  # Get the index of the current node\n#     # h_u = emb[u].unsqueeze(0)  # Embedding of node u, shape: (1, embedding_dim)\n    \n#     # # Calculate cosine similarity between h_u and all node embeddings\n#     # cos_sim = F.cosine_similarity(h_u, emb, dim=1)\n    \n#     # # Set the score for the node itself (u) to a very low value (to avoid selecting the node itself)\n#     # cos_sim[u] = -float('inf')\n    \n#     # # Get the top-k most similar nodes\n#     # topk_scores, topk_indices = torch.topk(cos_sim, k)  # Get top-5 most similar nodes\n    \n#     # # Convert indices back to node IDs (if necessary)\n#     # preds = [inv_map[idx] for idx in topk_indices.tolist()]\n#     u = mapping[nid]  # Get the index of the current node\n#     h_u = emb[u].unsqueeze(0)  # Shape: (1, embedding_dim)\n    \n#     # Compute dot product with all node embeddings\n#     dot_sim = torch.matmul(emb, h_u.T).squeeze(1)  # Shape: (num_nodes,)\n    \n#     # Set self-score to -inf to avoid selecting the node itself\n#     dot_sim[u] = -float('inf')\n    \n#     # Get the top-k most similar nodes\n#     topk_scores, topk_indices = torch.topk(dot_sim, k)\n    \n#     # Convert indices back to node IDs\n#     preds = [inv_map[idx] for idx in topk_indices.tolist()]\n\n    \n#     # Actual neighbors in the graph\n#     actual = set(G.successors(nid))\n    \n#     # Evaluation metrics\n#     hit = any(p in actual for p in preds)\n#     correct = sum(1 for p in preds if p in actual)\n#     precision = correct / len(preds) if preds else 0\n#     recall = correct / len(actual) if actual else 0\n    \n#     # # Print results\n#     # print(f'Node {nid}: Predicted={preds}, Actual={list(actual)}, Hit={hit}')\n#     # print(f'Precision={precision:.2f}, Recall={recall:.2f}')\n#     # print(\"==============================================\")\n#     if(hit):\n#         cnt += 1\n# print(cnt/6003)\n\n# # for nid in test_nodes[30:40]:\n# #     u = mapping[nid]\n# #     h_u = emb[u].unsqueeze(0)\n# #     h_u_rep = h_u.repeat(emb.size(0), 1)\n# #     pair = torch.cat([h_u_rep, emb], dim=1)\n# #     print(pair)\n# #     scores = (pair @ lin_weight.t()).view(-1) + lin_bias\n# #     scores[u] = -float('inf')\n# #     topk = torch.topk(scores, k).indices.tolist()\n\n# #     preds = [inv_map[idx] for idx in topk]\n# #     actual = set(G.successors(nid))\n# #     hit = any(p in actual for p in preds)\n# #     correct = sum(1 for p in preds if p in actual)\n# #     precision = correct / len(preds) if preds else 0\n# #     recall = correct / len(actual) if actual else 0\n# #     print(f'Node {nid}: Predicted={preds}, Actual={list(actual)}, Hit={hit}')\n# #     print(f'Precision={precision:.2f}, Recall={recall:.2f}')\n# #     print(\"==============================================\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T06:10:53.963379Z","iopub.execute_input":"2025-05-05T06:10:53.963683Z","iopub.status.idle":"2025-05-05T06:10:55.720484Z","shell.execute_reply.started":"2025-05-05T06:10:53.963659Z","shell.execute_reply":"2025-05-05T06:10:55.719753Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2849003629.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  emb = torch.load(emb_path)\n","output_type":"stream"},{"name":"stdout","text":"6003\n0.4331167749458604\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# print(G.number_of_edges(), G.number_of_nodes())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:37:14.742852Z","iopub.execute_input":"2025-05-05T03:37:14.743811Z","iopub.status.idle":"2025-05-05T03:37:14.750001Z","shell.execute_reply.started":"2025-05-05T03:37:14.743781Z","shell.execute_reply":"2025-05-05T03:37:14.749368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(state.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:43:57.111938Z","iopub.execute_input":"2025-05-05T03:43:57.112819Z","iopub.status.idle":"2025-05-05T03:43:57.117040Z","shell.execute_reply.started":"2025-05-05T03:43:57.112792Z","shell.execute_reply":"2025-05-05T03:43:57.116191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-geometric\n!pip install rapidfuzz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:28:49.257707Z","iopub.execute_input":"2025-05-05T17:28:49.258255Z","iopub.status.idle":"2025-05-05T17:28:56.869229Z","shell.execute_reply.started":"2025-05-05T17:28:49.258231Z","shell.execute_reply":"2025-05-05T17:28:56.868455Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rapidfuzz\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz\nSuccessfully installed rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import argparse\nimport networkx as nx\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport random # Added for shuffling nodes\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GraphSAGE\nfrom torch_geometric.data import Data\nfrom torch_geometric.utils import negative_sampling, to_networkx, subgraph # Added subgraph\nfrom torch_geometric.loader import NeighborLoader\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfrom tqdm import tqdm\nimport re\nfrom rapidfuzz import process, fuzz\n\n# --- GRAPH BUILDER CODE (Keep as is) ---\ndef extract_brace_content(text, start_idx):\n    # ... (keep original function)\n    assert text[start_idx] == '{'\n    depth = 0\n    i = start_idx\n    while i < len(text):\n        if text[i] == '{':\n            depth += 1\n        elif text[i] == '}':\n            depth -= 1\n            if depth == 0:\n                return text[start_idx+1:i], i + 1\n        i += 1\n    return \"\", i\n\ndef parse_bbl(bbl_path='t.bbl'):\n    # ... (keep original function)\n    try:\n        with open(bbl_path, 'r', encoding='utf8') as f:\n            text = f.read()\n    except UnicodeDecodeError:\n        with open(bbl_path, 'r', encoding='latin-1') as f:\n            text = f.read()\n\n    titles = []\n\n    # 1. BibLaTeX \\entry{...} blocks\n    entry_blocks = re.findall(r'\\\\entry\\{.*?\\}\\{.*?\\}\\{.*?\\}(.*?)\\\\endentry', text, flags=re.DOTALL)\n    for block in entry_blocks:\n        idx = block.find(r'\\field{title}')\n        if idx != -1:\n            brace_start = block.find('{', idx + len(r'\\field{title}'))\n            if brace_start != -1:\n                raw_title, _ = extract_brace_content(block, brace_start)\n                title = clean_title(raw_title)\n                titles.append(title)\n\n    # 2. \\bib{key}{type}{...} blocks\n    bib_blocks = re.findall(r'\\\\bib\\{.*?\\}\\{.*?\\}\\{(.*?)\\n\\}', text, flags=re.DOTALL)\n    for block in bib_blocks:\n        match = re.search(r'title\\s*=\\s*\\{(.*?)\\}', block, flags=re.DOTALL)\n        if match:\n            title = clean_title(match.group(1))\n            titles.append(title)\n\n    # 3. \\bibitem blocks\n    bibitems = re.split(r\"\\\\bibitem(?:\\[[^\\]]*\\]){0,3}\\{.*?\\}\", text)[1:]\n    for block in bibitems:\n        title = None\n\n        # (a) \\showarticletitle{...}\n        match = re.search(r'\\\\showarticletitle\\s*\\{(.*?)\\}', block, flags=re.DOTALL)\n        if match:\n            title = clean_title(match.group(1))\n        else:\n            # (b) \\newblock ...\n            parts = re.split(r\"\\\\newblock\", block)\n            if len(parts) >= 2:\n                title = clean_title(parts[1])\n            else:\n                # (c) ``...'' quoted title\n                quote_match = re.search(r\"``(.*?)''\", block, flags=re.DOTALL)\n                if quote_match:\n                    title = clean_title(quote_match.group(1))\n                else:\n                    # (d) : {Title}\n                    colon_title = re.search(r':[ \\n]*\\{(.*?)\\}', block, flags=re.DOTALL)\n                    if colon_title:\n                        title = clean_title(colon_title.group(1))\n\n        if title:\n            titles.append(title)\n\n    # 4. Handle cases like \\url{...}\n    urls = re.findall(r'\\\\url\\{(.*?)\\}', text)\n    for url in urls:\n        # Optionally, save URLs if needed\n        pass\n    # if len(titles)==0:\n    #     print(bbl_path)\n    return titles\n\n\ndef parse_bib(bib_file_path):\n    # ... (keep original function)\n    try:\n        with open(bib_file_path, 'r', encoding='utf8') as f:\n            bib_string = f.read()\n    except UnicodeDecodeError:\n        with open(bib_file_path, 'r', encoding='latin-1') as f:\n            bib_string = f.read()\n\n    pattern = r'(?:^|\\n|,\\s*)title\\s*=\\s*(?:\\{|\")(.*?)(?:\\}|\")'\n    matches = re.findall(pattern, bib_string, flags=re.IGNORECASE | re.DOTALL)\n\n    cleaned_titles = []\n    for title in matches:\n        title = title.strip()\n        cleaned_titles.append(re.sub(r\"^[\\{\\}]+|[\\{\\}]+$\", \"\", title).strip())\n\n    return cleaned_titles\n\n\ndef clean_title(raw):\n    # ... (keep original function)\n    raw = raw.replace('\\n', ' ')\n    raw = re.sub(r'\\s+', ' ', raw)\n    raw = re.sub(r'\\{\\\\[a-zA-Z]+\\s+(.*?)\\}', r'\\1', raw)  # {\\em foo} → foo\n    raw = re.sub(r'\\\\[a-zA-Z]+\\s*', '', raw)              # \\em, \\url, etc\n    raw = re.sub(r'[{}]', '', raw)                       # remove braces\n    return raw.strip(' .')\n\n\ndef build_title_map(data_dir):\n    # ... (keep original function)\n    title_map = {}\n    cnt = 0\n    all_files = os.listdir(data_dir)\n    print(f\"Total items in data_dir: {len(all_files)}\")\n    for paper in tqdm(all_files, desc=\"Building title map\"):\n        pap_dir = os.path.join(data_dir, paper)\n        tfile = os.path.join(pap_dir, 'title.txt')\n        # Ensure it's a directory corresponding to a paper ID format if needed\n        # Example check: if os.path.isdir(pap_dir) and re.match(r'^\\d+$', paper):\n        if os.path.isdir(pap_dir) and os.path.isfile(tfile):\n            try:\n                with open(tfile, 'r', encoding='utf8') as f:\n                    title_map[paper] = f.read().strip()\n            except Exception as e:\n                print(f\"Warning: Could not read title for {paper}: {e}\")\n        # else:\n        #     print(f\"Skipping {paper}, not a valid paper directory or title.txt missing.\") # Optional debug\n    print(f\"Found {len(title_map)} papers with titles.\")\n    return title_map\n\ndef build_references(data_dir, paper_ids):\n    # ... (Modifications: only process known paper_ids)\n    \"\"\"Map paper_id -> list of reference titles for given paper_ids.\"\"\"\n    refs = {}\n    # print(f\"Building references for {len(paper_ids)} papers.\")\n    for paper in tqdm(paper_ids, desc=\"Building references\"): # Iterate through provided paper IDs\n        pap_dir = os.path.join(data_dir, paper)\n        if not os.path.isdir(pap_dir):\n            # print(f\"Directory not found for paper {paper}, skipping.\") # Optional debug\n            continue\n\n        found_ref_file = False\n        # Prioritize .bbl\n        for fname in os.listdir(pap_dir):\n            if fname.endswith('.bbl'):\n                bbl_path = os.path.join(pap_dir, fname)\n                try:\n                    refs[paper] = parse_bbl(bbl_path)\n                    found_ref_file = True\n                    # print(f\"Found {len(refs[paper])} refs in {fname} for {paper}\") # Optional debug\n                    break\n                except Exception as e:\n                    print(f\"Warning: Could not parse {bbl_path}: {e}\")\n                    refs[paper] = [] # Assign empty list on error\n\n        # Fallback to .bib if no .bbl found or parsed successfully\n        if not found_ref_file:\n            for fname in os.listdir(pap_dir):\n                if fname.endswith('.bib'):\n                    bib_path = os.path.join(pap_dir, fname)\n                    try:\n                        refs[paper] = parse_bib(bib_path)\n                        found_ref_file = True\n                        # print(f\"Found {len(refs[paper])} refs in {fname} for {paper}\") # Optional debug\n                        break\n                    except Exception as e:\n                        print(f\"Warning: Could not parse {bib_path}: {e}\")\n                        refs[paper] = [] # Assign empty list on error\n\n        if not found_ref_file:\n             # print(f\"No .bbl or .bib found for {paper}\") # Optional debug\n             refs[paper] = [] # Ensure entry exists even if no refs found\n\n    print(f\"Built reference lists for {len(refs)} papers.\")\n    return refs\n\n\ndef match_refs_to_papers(refs, title_map, threshold=80):\n    \"\"\"Fuzzy match reference titles to known paper titles.\"\"\"\n    graph = nx.DiGraph()\n    known_pids = list(title_map.keys()) # Nodes are based on title_map keys\n\n    # Add nodes that have titles\n    for pid in known_pids:\n        graph.add_node(pid)\n\n    titles = list(title_map.values())\n    # Create reverse mapping only once\n    pid_by_title = {v: k for k, v in title_map.items()}\n\n    print(f\"Matching references for {len(refs)} source papers against {len(titles)} target titles.\")\n    for src, rlist in tqdm(refs.items(), desc='Matching refs'):\n        if src not in graph: # Ensure source node exists in our known set\n             # print(f\"Warning: Source paper {src} not in title_map, skipping its references.\") # Optional Debug\n             continue\n        if not rlist: # Skip if no references were parsed for this paper\n            continue\n\n        # --- Loop through each reference title for the current source paper ---\n        for ref in rlist:\n            # Add a basic check for valid reference string to avoid errors with process.extract\n            if not ref or not isinstance(ref, str) or len(ref.strip()) < 5: # Skip empty, non-string, or very short refs\n                continue\n\n            # --- Perform fuzzy matching for the *current* reference 'ref' ---\n            # Option 1: Using extract (finds multiple matches above threshold)\n            extracted_matches = process.extract(ref, titles, scorer=fuzz.token_set_ratio, score_cutoff=threshold)\n\n            # Process the matches found for this specific 'ref'\n            for match_title, score, _ in extracted_matches:\n                tgt = pid_by_title.get(match_title) # Look up PID from matched title\n                # Ensure target node exists in our graph nodes AND is not the source itself (optional)\n                if tgt and tgt in graph:\n                    # Optional: Prevent self-citations if desired\n                    # if src == tgt:\n                    #     continue\n                    # Add edge only if it doesn't exist to avoid parallel edges if multiple refs match same target\n                    if not graph.has_edge(src, tgt):\n                        graph.add_edge(src, tgt)\n                        # If you only want the *best* match per reference, you could break here\n                        # break # Uncomment if you only want the first match above threshold per 'ref'\n\n\n            # --- Option 2: Alternative using extractOne (finds only the single best match >= threshold) ---\n            # Uncomment this block and comment out the 'Option 1' block above if you prefer extractOne\n            # match_result = process.extractOne(ref, titles, scorer=fuzz.token_set_ratio, score_cutoff=threshold) # Use score_cutoff\n            # if match_result: # Check if a match was found above the threshold\n            #     match_title, score, _ = match_result\n            #     tgt = pid_by_title.get(match_title)\n            #     if tgt and tgt in graph:\n            #         # Optional: Prevent self-citations\n            #         # if src == tgt:\n            #         #     continue\n            #         if not graph.has_edge(src, tgt):\n            #             graph.add_edge(src, tgt)\n            # --- End Alternative ---\n\n    print(f\"Graph created with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n    return graph\n\n# --- INVOCATION OF GRAPH BUILDER ---\ndef generate_graphml(data_dir, out_path):\n    print(\"Building title map...\")\n    title_map = build_title_map(data_dir)\n    if not title_map:\n        print(\"Error: No titles found. Cannot build graph.\")\n        return None\n\n    print(\"Building references...\")\n    # Pass only the paper IDs that have titles\n    refs = build_references(data_dir, list(title_map.keys()))\n\n    print(\"Matching references to papers...\")\n    G = match_refs_to_papers(refs, title_map)\n\n    print(f\"Writing graph to {out_path}...\")\n    nx.write_graphml(G, out_path)\n    print(f\"Graph stats: Nodes={G.number_of_nodes()}, Edges={G.number_of_edges()}\")\n    return G\n\n# --- MODEL AND TRAINING ---\n\n# 1. Prepare text embeddings (keep SentenceTransformer initialization global if needed)\n# Consider moving initialization inside relevant functions if memory is tight\n# sbert = SentenceTransformer('all-MiniLM-L6-v2') # Keep commented if loaded later\n\nclass LinkPredictor(torch.nn.Module):\n    def __init__(self, in_dim=384, hidden=128, num_layers=2):\n        super().__init__()\n        self.sage = GraphSAGE(in_channels=in_dim, hidden_channels=hidden, num_layers=num_layers, out_channels=hidden) # Explicitly set out_channels\n        # No linear layer needed for dot product score\n\n    def forward(self, x, edge_index):\n         # Only encode nodes using GraphSAGE\n        h = self.sage(x, edge_index)\n        return h # Return node embeddings\n\n    def decode(self, h, edge_label_index):\n        # Decode links using dot product\n        return (h[edge_label_index[0]] * h[edge_label_index[1]]).sum(dim=1)\n\n\n# --- MODIFIED GRAPH LOADING ---\ndef load_full_graph_data(graph_path):\n    \"\"\"Loads the full graph and creates mappings.\"\"\"\n    print(f\"Loading full graph from {graph_path}...\")\n    if not os.path.exists(graph_path):\n         raise FileNotFoundError(f\"Graph file not found: {graph_path}\")\n    Gnx = nx.read_graphml(graph_path)\n    print(f\"Full graph loaded: {Gnx.number_of_nodes()} nodes, {Gnx.number_of_edges()} edges.\")\n\n    nodes = list(Gnx.nodes())\n    mapping = {nid: i for i, nid in enumerate(nodes)}\n    inv_mapping = {i: nid for nid, i in mapping.items()}\n\n    edges = [[mapping[u], mapping[v]] for u, v in Gnx.edges() if u in mapping and v in mapping]\n    if not edges:\n        print(\"Warning: No edges found or mapped in the graph!\")\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    else:\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n    print(f\"Full edge_index created with shape: {edge_index.shape}\")\n    return Gnx, edge_index, mapping, inv_mapping\n\n\n# --- TEXT EMBEDDING LOADING ---\ndef load_text_embeddings(data_dir, node_list, mapping, device):\n    \"\"\"Loads or computes text embeddings for a given list of nodes.\"\"\"\n    # Ensure mapping covers all nodes in node_list\n    if not all(nid in mapping for nid in node_list):\n         missing = [nid for nid in node_list if nid not in mapping]\n         print(f\"Warning: {len(missing)} nodes in node_list are not in the provided mapping. This might cause index errors.\")\n         # Option 1: Filter node_list (if subsequent code handles potential missing nodes)\n         # node_list = [nid for nid in node_list if nid in mapping]\n         # Option 2: Raise an error\n         raise ValueError(f\"Mapping is incomplete for node_list. Missing: {missing[:5]}...\")\n\n\n    sbert = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n    emb_dim = 384 # SBERT embedding dimension\n    # Initialize embeddings for all nodes covered by the mapping\n    x = torch.zeros((len(mapping), emb_dim), dtype=torch.float, device=device)\n    print(f\"Initialized embedding tensor shape: {x.shape}\")\n\n    processed_count = 0\n    for nid in tqdm(node_list, desc='Embedding texts'):\n        if nid not in mapping:\n             # print(f\"Skipping node {nid} as it's not in the mapping.\") # Already warned above\n             continue\n\n        idx = mapping[nid]\n        txt = ''\n        nid_path = os.path.join(data_dir, str(nid)) # Ensure nid is string for path join\n        # print(f\"Processing node {nid} (index {idx}), path: {nid_path}\") # Debug\n\n        for fname in ('title.txt', 'abstract.txt'):\n            path = os.path.join(nid_path, fname)\n            if os.path.isfile(path):\n                try:\n                    with open(path, 'r', encoding='utf8') as f:\n                        txt += f.read().strip() + ' '\n                except Exception as e:\n                    print(f\"Warning: Could not read {path}: {e}\")\n\n        if txt.strip():\n            try:\n                # Ensure input is not excessively long (optional safeguard)\n                max_len = 512 # Example limit, adjust as needed\n                if len(txt.split()) > max_len:\n                     txt = ' '.join(txt.split()[:max_len])\n\n                emb = sbert.encode(txt.strip(), convert_to_tensor=True, show_progress_bar=False)\n                # print(f\"Node {nid}: Text length={len(txt.strip())}, Emb shape={emb.shape}\") # Debug\n                if emb.shape[0] == emb_dim:\n                    x[idx] = emb.to(device) # Ensure tensor is on the correct device\n                    processed_count += 1\n                else:\n                    print(f\"Warning: Embedding for node {nid} has unexpected shape {emb.shape}. Skipping.\")\n            except Exception as e:\n                print(f\"Error encoding text for node {nid}: {e}\")\n                # Optionally handle error, e.g., skip node or use zero vector\n        # else:\n            # print(f\"Node {nid}: No text found in title.txt or abstract.txt.\") # Debug\n\n    print(f\"Successfully processed and embedded text for {processed_count} nodes out of {len(node_list)} requested.\")\n\n    # Normalize embeddings\n    x = F.normalize(x, p=2, dim=1)\n    # Replace NaNs resulting from normalizing zero vectors (if any)\n    x = torch.nan_to_num(x)\n    print(\"Embeddings normalized.\")\n\n    return x\n\n\n# --- MODIFIED TRAINING FUNCTION ---\ndef train(args, x_train, edge_index_train, train_nodes_indices, device):\n    print(f\"Starting training on {device}...\")\n    print(f\"Training data: Nodes={x_train.size(0)}, Edges={edge_index_train.size(1)}\")\n\n    # Ensure data is on the correct device\n    x_train = x_train.to(device)\n    edge_index_train = edge_index_train.to(device)\n\n    # Split edges *within the training graph* for training and validation\n    num_train_edges = edge_index_train.size(1)\n    if num_train_edges == 0:\n        print(\"Error: No edges in the training graph. Cannot train.\")\n        return None, None\n\n    perm = torch.randperm(num_train_edges, device=device) # Generate permutation on the correct device\n    val_cnt = int(args.val_ratio * num_train_edges)\n    val_idx = perm[:val_cnt]\n    train_idx = perm[val_cnt:]\n\n    pos_train_edges = edge_index_train[:, train_idx]\n    pos_val_edges = edge_index_train[:, val_idx]\n\n    print(f\"Positive edges split: Train={pos_train_edges.size(1)}, Val={pos_val_edges.size(1)}\")\n\n    # --- Create a reduced edge_index for message passing during training ---\n    # This index should *only* contain the positive training edges.\n    # The validation edges are held out and not used for message passing.\n    train_msg_passing_edge_index = pos_train_edges\n\n    model = LinkPredictor(in_dim=x_train.size(1), hidden=args.hidden_dim, num_layers=args.num_layers).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n    print(\"Model and optimizer initialized.\")\n\n    best_val_loss = float('inf')\n    epochs_no_improve = 0\n    patience = 50 # Stop training if validation loss doesn't improve for 'patience' epochs\n\n    for epoch in range(1, args.epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n\n        # Use only training edges for message passing\n        h_train = model(x_train, train_msg_passing_edge_index)\n\n        # Sample negative edges for training *within the training graph*\n        # Ensure negative sampling operates correctly on the number of training nodes\n        num_train_nodes = x_train.size(0)\n        neg_train_edges = negative_sampling(\n            edge_index=edge_index_train, # Sample based on all edges in train graph to avoid sampling existing links\n            num_nodes=num_train_nodes,\n            num_neg_samples=pos_train_edges.size(1),\n            method='sparse'\n        ).to(device)\n\n        # Decode positive and negative training edges\n        pos_train_logits = model.decode(h_train, pos_train_edges)\n        neg_train_logits = model.decode(h_train, neg_train_edges)\n\n        # Calculate training loss\n        pos_train_loss = F.binary_cross_entropy_with_logits(pos_train_logits, torch.ones_like(pos_train_logits))\n        neg_train_loss = F.binary_cross_entropy_with_logits(neg_train_logits, torch.zeros_like(neg_train_logits))\n        train_loss = (pos_train_loss + neg_train_loss) / 2\n\n        train_loss.backward()\n        # Optional: Gradient clipping\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        # --- Validation ---\n        model.eval()\n        with torch.no_grad():\n            # Note: For validation, we still use the embeddings (h_train) generated\n            # using ONLY the training message passing edges. We are evaluating how well\n            # these embeddings predict the held-out validation links.\n            h_val = h_train # Use the same embeddings\n\n            # Sample negative edges for validation\n            neg_val_edges = negative_sampling(\n                edge_index=edge_index_train,\n                num_nodes=num_train_nodes,\n                num_neg_samples=pos_val_edges.size(1),\n                method='sparse'\n            ).to(device)\n\n            # Decode positive and negative validation edges\n            pos_val_logits = model.decode(h_val, pos_val_edges)\n            neg_val_logits = model.decode(h_val, neg_val_edges)\n\n            # Calculate validation loss\n            pos_val_loss = F.binary_cross_entropy_with_logits(pos_val_logits, torch.ones_like(pos_val_logits))\n            neg_val_loss = F.binary_cross_entropy_with_logits(neg_val_logits, torch.zeros_like(neg_val_logits))\n            val_loss = (pos_val_loss + neg_val_loss) / 2\n\n        print(f'Epoch {epoch}/{args.epochs} | Train Loss: {train_loss.item():.4f} | Val Loss: {val_loss.item():.4f}')\n\n        # --- Early Stopping ---\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            epochs_no_improve = 0\n            # Save the best model state\n            torch.save(model.state_dict(), args.out_model_path)\n            print(f\"Validation loss improved. Saved model to {args.out_model_path}\")\n        else:\n            epochs_no_improve += 1\n\n        if epochs_no_improve >= patience:\n            print(f\"Validation loss did not improve for {patience} epochs. Early stopping.\")\n            break\n\n    # --- Post-Training ---\n    # Load the best model state\n    print(f\"Loading best model state from {args.out_model_path}\")\n    model.load_state_dict(torch.load(args.out_model_path, map_location=device))\n    model.eval()\n\n    # Generate final embeddings for the training nodes using the best model\n    # Use the full training edge index (pos_train + pos_val) for generating final embeddings\n    print(\"Generating final embeddings for training nodes using the best model...\")\n    with torch.no_grad():\n        final_emb_train = model(x_train, edge_index_train).cpu() # Move to CPU for saving/analysis\n\n    print(f\"Final training node embeddings shape: {final_emb_train.shape}\")\n\n    # --- Sanity check embeddings (optional) ---\n    # with torch.no_grad():\n    #     per_node_std = final_emb_train.std(dim=1)\n    #     per_node_mean = final_emb_train.mean(dim=1)\n    #     print(\"Embedding stats for training nodes:\")\n    #     # print(f\"Std[:10]: {per_node_std[:10]}\")\n    #     # print(f\"Mean[:10]: {per_node_mean[:10]}\")\n    #     print(f\"Mean of per-node std: {per_node_std.mean().item():.6f}\")\n    #     print(f\"Mean of per-node mean: {per_node_mean.mean().item():.6f}\")\n    #     print(f\"NaN count in embeddings: {torch.isnan(final_emb_train).sum().item()}\")\n\n\n    print('Training complete.')\n    # The model state is already saved (best validation score)\n    # Return the model (in eval mode) and the final training embeddings\n    return model, final_emb_train\n\n\n# --- Configuration Class ---\nclass Config:\n    # --- Paths ---\n    data_dir = '/kaggle/input/papers/dataset_papers' # Source data directory\n    graph_dir = '/kaggle/working/' # Directory to save/load the graphml\n    output_dir = '/kaggle/working/' # Directory for model outputs\n    graph_name = 'citation_graph.graphml'\n    model_name = 'linkpred_model_final.pt'\n    embeddings_name = 'node_embeddings_final.pt' # For all nodes after inference\n    text_embeddings_cache = '/kaggle/input/text-embeddings/text_embeddings.pt' # Cache for initial text embeds\n\n    # --- Graph Generation ---\n    generate_graph = False # Set to False if graphml already exists\n\n    # --- Data Split ---\n    test_node_ratio = 0.05 # Hold out 5% of nodes for testing\n    val_ratio = 0.05 # Use 10% of *training graph edges* for validation during training\n\n    # --- Model & Training ---\n    hidden_dim = 64\n    num_layers = 3\n    epochs = 1000 # Reduced epochs for potentially faster convergence with early stopping\n    lr = 2e-2 # Adjusted learning rate\n    device = 'cpu' if torch.cuda.is_available() else 'cpu'\n    weight_decay = 1e-4\n    # --- Inference ---\n    k = 10 # Top-k predictions for evaluation\n\n    # --- Derived Paths ---\n    @property\n    def graph_path(self):\n        if not self.generate_graph:\n            return '/kaggle/input/final-graph/final_citations_graph.graphml'\n        return os.path.join(self.graph_dir, self.graph_name)\n\n    @property\n    def out_model_path(self):\n        return os.path.join(self.output_dir, self.model_name)\n\n    @property\n    def out_embeddings_path(self):\n        return os.path.join(self.output_dir, self.embeddings_name)\n\n# --- Main Workflow ---\ndef main_workflow():\n    args = Config()\n    device = torch.device(args.device)\n    print(f\"Using device: {device}\")\n    os.makedirs(args.graph_dir, exist_ok=True)\n    os.makedirs(args.output_dir, exist_ok=True)\n\n    # 1. Generate or Load Full Graph\n    if args.generate_graph or not os.path.exists(args.graph_path):\n        print(\"Generating GraphML file...\")\n        G_full = generate_graphml(args.data_dir, args.graph_path)\n        if G_full is None:\n            print(\"Graph generation failed. Exiting.\")\n            return\n    else:\n        print(f\"Loading existing graph from {args.graph_path}\")\n        G_full = nx.read_graphml(args.graph_path)\n\n    if G_full.number_of_nodes() == 0:\n         print(\"Error: Loaded graph has no nodes. Check graph generation/loading.\")\n         return\n\n    # 2. Load Full Graph Data (Edges, Mappings)\n    G_full, edge_index_full, mapping_full, inv_map_full = load_full_graph_data(args.graph_path)\n    all_node_ids = list(G_full.nodes())\n    num_all_nodes = len(all_node_ids)\n    print(f\"Total nodes in graph: {num_all_nodes}\")\n    if num_all_nodes == 0:\n        print(\"Error: No nodes found in the loaded graph.\")\n        return\n\n    # 3. Load or Generate Initial Text Embeddings (for ALL nodes)\n    if os.path.exists(args.text_embeddings_cache):\n        print(f\"Loading cached text embeddings from {args.text_embeddings_cache}\")\n        x_full = torch.load(args.text_embeddings_cache, map_location='cpu').to(device) # Load to CPU first, then move\n        # Verify shape consistency\n        if x_full.shape[0] != num_all_nodes:\n             print(f\"Warning: Cached embeddings shape ({x_full.shape[0]}) doesn't match number of nodes ({num_all_nodes}). Recomputing.\")\n             x_full = load_text_embeddings(args.data_dir, all_node_ids, mapping_full, device)\n             torch.save(x_full.cpu(), args.text_embeddings_cache) # Save the recomputed embeddings\n        else:\n             print(\"Cached text embeddings loaded successfully.\")\n\n    else:\n        print(\"Generating initial text embeddings for all nodes...\")\n        x_full = load_text_embeddings(args.data_dir, all_node_ids, mapping_full, device)\n        print(f\"Saving text embeddings to cache: {args.text_embeddings_cache}\")\n        torch.save(x_full.cpu(), args.text_embeddings_cache) # Save to CPU\n\n    if x_full is None or x_full.shape[0] != num_all_nodes:\n        print(\"Error: Failed to load or generate initial text embeddings correctly.\")\n        return\n    print(f\"Full text embeddings shape: {x_full.shape}\")\n\n\n    # 4. Split Nodes into Train and Test Sets\n    print(f\"Splitting nodes into training and testing sets ({1-args.test_node_ratio:.0%} train, {args.test_node_ratio:.0%} test)...\")\n    if len(all_node_ids) < 2: # Need at least 2 nodes for train/test split\n        print(\"Error: Not enough nodes to perform train/test split.\")\n        return\n\n    try:\n        train_node_ids, test_node_ids = train_test_split(\n            all_node_ids,\n            test_size=args.test_node_ratio,\n            random_state=42 # for reproducibility\n        )\n    except ValueError as e:\n        print(f\"Error during train/test split: {e}. Check node list and test_size.\")\n        # Fallback: If test_size is too small or causes issues with very few nodes\n        if len(all_node_ids) > 0:\n             print(\"Fallback: Assigning all nodes to training due to split error.\")\n             train_node_ids = all_node_ids\n             test_node_ids = []\n        else:\n             print(\"Cannot proceed with zero nodes.\")\n             return\n\n\n    num_train_nodes = len(train_node_ids)\n    num_test_nodes = len(test_node_ids)\n    print(f\"Training nodes: {num_train_nodes}, Testing nodes: {num_test_nodes}\")\n\n    if num_train_nodes == 0:\n        print(\"Error: No nodes assigned to the training set. Cannot train.\")\n        return\n\n    # 5. Prepare Data for Training\n    # Get indices of training nodes in the full mapping\n    train_nodes_indices_full = torch.tensor([mapping_full[nid] for nid in train_node_ids], dtype=torch.long).to(device)\n\n    # Select corresponding initial embeddings for training nodes\n    x_train = x_full[train_nodes_indices_full]\n    print(f\"Training embeddings shape: {x_train.shape}\")\n\n\n    # Create the training edge_index (only edges *between* training nodes)\n    # Use PyG's subgraph utility\n    # device = torch.device(args.device)\n    # print(f\"Moving tensors to device: {device}\")\n    \n    # # Assuming these tensors are created from your graph processing\n    # edge_index_full = edge_index_full.to(device)\n    # # If you have node features, move them too:\n    # # x_full = x_full.to(device)\n    # # Move your node index tensors\n    # train_nodes_indices_full = train_nodes_indices_full.to(device)\n    # test_nodes_indices_full = test_nodes_indices_full.to(device)\n    # # Move any other tensors that will be used in device-specific operations\n    \n    # # --- Now call subgraph with tensors on the correct device ---\n    # # This part of your code remains the same, but the inputs are now on the right device\n    # edge_index_train, train_subgraph_edge_attr = subgraph(\n    #     subset=train_nodes_indices_full, # This is now on the device\n    #     edge_index=edge_index_full,     # This is now on the device\n    #     # edge_attr=edge_attr_full, # If you use edge attributes, move them too\n    #     relabel_nodes=True # Or False depending on your needs\n    #     # num_nodes=G_full.number_of_nodes() # Pass if relabeling\n    # )\n\n    edge_index_train, train_subgraph_edge_attr = subgraph(\n        subset=train_nodes_indices_full,\n        edge_index=edge_index_full,\n        relabel_nodes=True, # IMPORTANT: Relabel node indices to be 0 to num_train_nodes-1\n        num_nodes=num_all_nodes # Specify total number of nodes in original graph\n    )\n    # train_nodes_indices are now the relabeled indices (0 to N_train-1)\n    # We need a mapping from the *new* 0-based indices back to the original *full* indices if needed later,\n    # but the train function itself works with the relabeled indices and x_train directly.\n    print(f\"Training edge_index shape (relabeled): {edge_index_train.shape}\")\n\n\n    # 6. Train the Model\n    model, _ = train(args, x_train, edge_index_train, torch.arange(num_train_nodes), device) # Pass relabeled indices 0..N_train-1\n\n    if model is None:\n        print(\"Model training failed.\")\n        return\n\n    # 7. Inference: Generate Embeddings for ALL Nodes using the Trained Model\n    # print(\"Performing inference to generate embeddings for ALL nodes...\")\n    # model.eval() # Ensure model is in evaluation mode\n    # with torch.no_grad():\n    #     # Use the trained SAGE layers (`model.sage`) on the *full* graph and *full* initial features\n    #     # The `forward` method of LinkPredictor class IS the sage layer call\n    #     final_emb_full = model(x_full, edge_index_full).cpu() # Move to CPU\n\n    # print(f\"Final embeddings generated for all nodes. Shape: {final_emb_full.shape}\")\n    # print(f\"Saving final full embeddings to {args.out_embeddings_path}\")\n    # torch.save(final_emb_full, args.out_embeddings_path)\n    test_idx = torch.tensor([mapping_full[nid] for nid in test_node_ids], dtype=torch.long, device=device)\n    \n    # Create a mask that keeps only edges where neither endpoint is a test‐node\n    mask = ~(\n        torch.isin(edge_index_full[0], test_idx) |\n        torch.isin(edge_index_full[1], test_idx)\n    )\n    \n    # Apply the mask to filter out any edge touching a test node\n    edge_index_no_test = edge_index_full[:, mask]\n    \n    # Now use this filtered edge_index for inference\n    print(\"Performing inference with test‐nodes isolated…\")\n    model.eval()\n    with torch.no_grad():\n        final_emb_full = model(x_full, edge_index_no_test).cpu()\n\n    print(f\"Final embeddings generated for all nodes. Shape: {final_emb_full.shape}\")\n    print(f\"Saving final full embeddings to {args.out_embeddings_path}\")\n    torch.save(final_emb_full, args.out_embeddings_path)\n\n\n\n    # 8. Evaluate on Test Nodes\n    print(f\"\\n--- Evaluating on {num_test_nodes} Test Nodes ---\")\n    if num_test_nodes == 0:\n        print(\"No test nodes to evaluate.\")\n        return\n\n    # Use the final embeddings generated in step 7\n    emb_eval = final_emb_full.to(device) # Move back to device if needed for calculations\n    print(emb_eval.shape)\n    total_hit = 0\n    total_precision = 0\n    total_recall = 0\n    evaluated_nodes = 0\n\n    for test_nid in tqdm(test_node_ids, desc=\"Evaluating test nodes\"):\n        if test_nid not in mapping_full:\n            print(f\"Warning: Test node {test_nid} not found in full mapping. Skipping.\")\n            continue\n\n        u_idx_full = mapping_full[test_nid] # Index in the full graph/embedding tensor\n        h_u = emb_eval[u_idx_full].unsqueeze(0) # Embedding of the test node\n\n        # Calculate scores (dot product) between the test node and ALL other nodes\n        # Ensure dimensions match for matmul: emb_eval (N, D), h_u.T (D, 1) -> scores (N, 1) -> squeeze -> (N,)\n        scores = torch.matmul(emb_eval, h_u.T).squeeze(1)\n\n        # Set score for the node itself to -inf to avoid self-prediction\n        scores[u_idx_full] = -float('inf')\n\n        # --- Optional: Exclude known training nodes from predictions ---\n        # If you ONLY want to predict links to OTHER UNSEEN (test) nodes:\n        # test_nodes_indices_full = torch.tensor([mapping_full[nid] for nid in test_node_ids], dtype=torch.long).to(device)\n        # scores[train_nodes_indices_full] = -float('inf') # Exclude training nodes\n        # --- Standard approach: Predict links to ANY node (train or test) ---\n        pass # Keep predictions for all other nodes\n\n        # Get top-k predictions based on scores\n        try:\n             # Ensure k is not larger than the number of possible prediction targets\n            effective_k = min(args.k, emb_eval.size(0) - 1) # -1 for self-node\n            if effective_k <=0:\n                 print(f\"Warning: Not enough other nodes to predict for node {test_nid}. Skipping k={args.k} prediction.\")\n                 continue # Skip if k becomes 0 or negative\n\n            topk_scores, topk_indices_full = torch.topk(scores, effective_k)\n\n            # Map predicted indices back to original node IDs\n            pred_node_ids = [inv_map_full[idx.item()] for idx in topk_indices_full]\n\n        except RuntimeError as e:\n            print(f\"Error during topk calculation for node {test_nid}: {e}. Scores shape: {scores.shape}, k={args.k}\")\n            continue # Skip this node if topk fails\n\n\n        # Get actual neighbors (successors) from the original full graph G_full\n        actual_neighbors = set(G_full.successors(test_nid))\n\n        if not actual_neighbors: # Skip evaluation if the test node has no outgoing links in reality\n            # print(f\"Node {test_nid} has no actual successors. Skipping eval for this node.\")\n            continue\n\n        # Calculate metrics\n        pred_set = set(pred_node_ids)\n        correct_preds = actual_neighbors.intersection(pred_set)\n\n        hit = 1 if len(correct_preds) > 0 else 0\n        precision = len(correct_preds) / len(pred_set) if pred_set else 0\n        recall = len(correct_preds) / len(actual_neighbors) if actual_neighbors else 0\n\n        total_hit += hit\n        total_precision += precision\n        total_recall += recall\n        evaluated_nodes += 1\n\n        # Optional: Print per-node results (can be verbose)\n        # print(f'Node {test_nid}: Pred={pred_node_ids}, Actual={list(actual_neighbors)}, Hit={hit}, Prec={precision:.2f}, Rec={recall:.2f}')\n\n    # Calculate average metrics\n    avg_hit_rate = total_hit / evaluated_nodes if evaluated_nodes > 0 else 0\n    avg_precision = total_precision / evaluated_nodes if evaluated_nodes > 0 else 0\n    avg_recall = total_recall / evaluated_nodes if evaluated_nodes > 0 else 0\n\n    print(\"\\n--- Evaluation Summary ---\")\n    print(f\"Evaluated on {evaluated_nodes} test nodes (nodes with actual outgoing links).\")\n    print(f\"Average Hit Rate @{args.k}: {avg_hit_rate:.4f}\")\n    print(f\"Average Precision @{args.k}: {avg_precision:.4f}\")\n    print(f\"Average Recall @{args.k}: {avg_recall:.4f}\")\n\n\nif __name__ == \"__main__\":\n    # Make sure to set the paths correctly in the Config class above\n    # Especially args.data_dir\n    main_workflow()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:08:20.407411Z","iopub.execute_input":"2025-05-05T18:08:20.407739Z","iopub.status.idle":"2025-05-05T18:08:48.923118Z","shell.execute_reply.started":"2025-05-05T18:08:20.407717Z","shell.execute_reply":"2025-05-05T18:08:48.922447Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nLoading existing graph from /kaggle/input/final-graph/final_citations_graph.graphml\nLoading full graph from /kaggle/input/final-graph/final_citations_graph.graphml...\nFull graph loaded: 6545 nodes, 28562 edges.\nFull edge_index created with shape: torch.Size([2, 28562])\nTotal nodes in graph: 6545\nLoading cached text embeddings from /kaggle/input/text-embeddings/text_embeddings.pt\nCached text embeddings loaded successfully.\nFull text embeddings shape: torch.Size([6545, 384])\nSplitting nodes into training and testing sets (95% train, 5% test)...\nTraining nodes: 6217, Testing nodes: 328\nTraining embeddings shape: torch.Size([6217, 384])\nTraining edge_index shape (relabeled): torch.Size([2, 25370])\nStarting training on cpu...\nTraining data: Nodes=6217, Edges=25370\nPositive edges split: Train=24102, Val=1268\nModel and optimizer initialized.\nEpoch 1/1000 | Train Loss: 0.7089 | Val Loss: 0.7087\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2875912480.py:626: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  x_full = torch.load(args.text_embeddings_cache, map_location='cpu').to(device) # Load to CPU first, then move\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/1000 | Train Loss: 1.3391 | Val Loss: 1.3357\nEpoch 3/1000 | Train Loss: 0.6920 | Val Loss: 0.6926\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 4/1000 | Train Loss: 0.7119 | Val Loss: 0.7151\nEpoch 5/1000 | Train Loss: 0.7000 | Val Loss: 0.7013\nEpoch 6/1000 | Train Loss: 0.6938 | Val Loss: 0.6937\nEpoch 7/1000 | Train Loss: 0.6724 | Val Loss: 0.6757\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 8/1000 | Train Loss: 0.8050 | Val Loss: 0.8044\nEpoch 9/1000 | Train Loss: 0.6668 | Val Loss: 0.6721\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 10/1000 | Train Loss: 0.6865 | Val Loss: 0.6870\nEpoch 11/1000 | Train Loss: 0.6975 | Val Loss: 0.6974\nEpoch 12/1000 | Train Loss: 0.7011 | Val Loss: 0.7010\nEpoch 13/1000 | Train Loss: 0.7027 | Val Loss: 0.7027\nEpoch 14/1000 | Train Loss: 0.7021 | Val Loss: 0.7022\nEpoch 15/1000 | Train Loss: 0.7002 | Val Loss: 0.6998\nEpoch 16/1000 | Train Loss: 0.6964 | Val Loss: 0.6975\nEpoch 17/1000 | Train Loss: 0.6900 | Val Loss: 0.6909\nEpoch 18/1000 | Train Loss: 0.6817 | Val Loss: 0.6820\nEpoch 19/1000 | Train Loss: 0.6732 | Val Loss: 0.6702\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 20/1000 | Train Loss: 0.6615 | Val Loss: 0.6595\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 21/1000 | Train Loss: 0.6544 | Val Loss: 0.6613\nEpoch 22/1000 | Train Loss: 0.6480 | Val Loss: 0.6558\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 23/1000 | Train Loss: 0.6367 | Val Loss: 0.6489\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 24/1000 | Train Loss: 0.6356 | Val Loss: 0.6491\nEpoch 25/1000 | Train Loss: 0.6302 | Val Loss: 0.6449\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 26/1000 | Train Loss: 0.6234 | Val Loss: 0.6308\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 27/1000 | Train Loss: 0.6205 | Val Loss: 0.6310\nEpoch 28/1000 | Train Loss: 0.6192 | Val Loss: 0.6263\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 29/1000 | Train Loss: 0.6154 | Val Loss: 0.6255\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 30/1000 | Train Loss: 0.6117 | Val Loss: 0.6253\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 31/1000 | Train Loss: 0.6098 | Val Loss: 0.6181\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 32/1000 | Train Loss: 0.6104 | Val Loss: 0.6174\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 33/1000 | Train Loss: 0.6057 | Val Loss: 0.6145\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 34/1000 | Train Loss: 0.6013 | Val Loss: 0.6135\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 35/1000 | Train Loss: 0.5985 | Val Loss: 0.6117\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 36/1000 | Train Loss: 0.5966 | Val Loss: 0.6008\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 37/1000 | Train Loss: 0.5932 | Val Loss: 0.6029\nEpoch 38/1000 | Train Loss: 0.5917 | Val Loss: 0.5923\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 39/1000 | Train Loss: 0.5889 | Val Loss: 0.5842\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 40/1000 | Train Loss: 0.5840 | Val Loss: 0.5886\nEpoch 41/1000 | Train Loss: 0.5795 | Val Loss: 0.5931\nEpoch 42/1000 | Train Loss: 0.5809 | Val Loss: 0.5937\nEpoch 43/1000 | Train Loss: 0.5860 | Val Loss: 0.6026\nEpoch 44/1000 | Train Loss: 0.5834 | Val Loss: 0.5914\nEpoch 45/1000 | Train Loss: 0.5776 | Val Loss: 0.5870\nEpoch 46/1000 | Train Loss: 0.5829 | Val Loss: 0.5943\nEpoch 47/1000 | Train Loss: 0.5742 | Val Loss: 0.5844\nEpoch 48/1000 | Train Loss: 0.5748 | Val Loss: 0.5891\nEpoch 49/1000 | Train Loss: 0.5707 | Val Loss: 0.5907\nEpoch 50/1000 | Train Loss: 0.5728 | Val Loss: 0.5844\nEpoch 51/1000 | Train Loss: 0.5685 | Val Loss: 0.5781\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 52/1000 | Train Loss: 0.5672 | Val Loss: 0.5782\nEpoch 53/1000 | Train Loss: 0.5680 | Val Loss: 0.5942\nEpoch 54/1000 | Train Loss: 0.5626 | Val Loss: 0.5682\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 55/1000 | Train Loss: 0.5614 | Val Loss: 0.5824\nEpoch 56/1000 | Train Loss: 0.5599 | Val Loss: 0.5648\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 57/1000 | Train Loss: 0.5589 | Val Loss: 0.5638\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 58/1000 | Train Loss: 0.5597 | Val Loss: 0.5720\nEpoch 59/1000 | Train Loss: 0.5590 | Val Loss: 0.5671\nEpoch 60/1000 | Train Loss: 0.5533 | Val Loss: 0.5673\nEpoch 61/1000 | Train Loss: 0.5592 | Val Loss: 0.5738\nEpoch 62/1000 | Train Loss: 0.5590 | Val Loss: 0.5589\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 63/1000 | Train Loss: 0.5546 | Val Loss: 0.5594\nEpoch 64/1000 | Train Loss: 0.5531 | Val Loss: 0.5658\nEpoch 65/1000 | Train Loss: 0.5550 | Val Loss: 0.5855\nEpoch 66/1000 | Train Loss: 0.5473 | Val Loss: 0.5697\nEpoch 67/1000 | Train Loss: 0.5512 | Val Loss: 0.5692\nEpoch 68/1000 | Train Loss: 0.5449 | Val Loss: 0.5572\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 69/1000 | Train Loss: 0.5481 | Val Loss: 0.5515\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 70/1000 | Train Loss: 0.5465 | Val Loss: 0.5563\nEpoch 71/1000 | Train Loss: 0.5458 | Val Loss: 0.5643\nEpoch 72/1000 | Train Loss: 0.5402 | Val Loss: 0.5547\nEpoch 73/1000 | Train Loss: 0.5430 | Val Loss: 0.5554\nEpoch 74/1000 | Train Loss: 0.5389 | Val Loss: 0.5591\nEpoch 75/1000 | Train Loss: 0.5432 | Val Loss: 0.5668\nEpoch 76/1000 | Train Loss: 0.5399 | Val Loss: 0.5640\nEpoch 77/1000 | Train Loss: 0.5413 | Val Loss: 0.5622\nEpoch 78/1000 | Train Loss: 0.5402 | Val Loss: 0.5503\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 79/1000 | Train Loss: 0.5400 | Val Loss: 0.5485\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 80/1000 | Train Loss: 0.5385 | Val Loss: 0.5488\nEpoch 81/1000 | Train Loss: 0.5381 | Val Loss: 0.5450\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 82/1000 | Train Loss: 0.5425 | Val Loss: 0.5446\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 83/1000 | Train Loss: 0.5345 | Val Loss: 0.5432\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 84/1000 | Train Loss: 0.5340 | Val Loss: 0.5525\nEpoch 85/1000 | Train Loss: 0.5347 | Val Loss: 0.5551\nEpoch 86/1000 | Train Loss: 0.5354 | Val Loss: 0.5550\nEpoch 87/1000 | Train Loss: 0.5367 | Val Loss: 0.5435\nEpoch 88/1000 | Train Loss: 0.5335 | Val Loss: 0.5440\nEpoch 89/1000 | Train Loss: 0.5380 | Val Loss: 0.5463\nEpoch 90/1000 | Train Loss: 0.5342 | Val Loss: 0.5458\nEpoch 91/1000 | Train Loss: 0.5342 | Val Loss: 0.5568\nEpoch 92/1000 | Train Loss: 0.5324 | Val Loss: 0.5371\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 93/1000 | Train Loss: 0.5347 | Val Loss: 0.5544\nEpoch 94/1000 | Train Loss: 0.5333 | Val Loss: 0.5528\nEpoch 95/1000 | Train Loss: 0.5366 | Val Loss: 0.5431\nEpoch 96/1000 | Train Loss: 0.5323 | Val Loss: 0.5382\nEpoch 97/1000 | Train Loss: 0.5311 | Val Loss: 0.5504\nEpoch 98/1000 | Train Loss: 0.5321 | Val Loss: 0.5514\nEpoch 99/1000 | Train Loss: 0.5311 | Val Loss: 0.5575\nEpoch 100/1000 | Train Loss: 0.5338 | Val Loss: 0.5453\nEpoch 101/1000 | Train Loss: 0.5341 | Val Loss: 0.5525\nEpoch 102/1000 | Train Loss: 0.5352 | Val Loss: 0.5412\nEpoch 103/1000 | Train Loss: 0.5340 | Val Loss: 0.5578\nEpoch 104/1000 | Train Loss: 0.5321 | Val Loss: 0.5397\nEpoch 105/1000 | Train Loss: 0.5303 | Val Loss: 0.5539\nEpoch 106/1000 | Train Loss: 0.5366 | Val Loss: 0.5368\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 107/1000 | Train Loss: 0.5329 | Val Loss: 0.5606\nEpoch 108/1000 | Train Loss: 0.5315 | Val Loss: 0.5515\nEpoch 109/1000 | Train Loss: 0.5310 | Val Loss: 0.5380\nEpoch 110/1000 | Train Loss: 0.5309 | Val Loss: 0.5482\nEpoch 111/1000 | Train Loss: 0.5306 | Val Loss: 0.5552\nEpoch 112/1000 | Train Loss: 0.5305 | Val Loss: 0.5434\nEpoch 113/1000 | Train Loss: 0.5300 | Val Loss: 0.5532\nEpoch 114/1000 | Train Loss: 0.5289 | Val Loss: 0.5535\nEpoch 115/1000 | Train Loss: 0.5286 | Val Loss: 0.5416\nEpoch 116/1000 | Train Loss: 0.5298 | Val Loss: 0.5468\nEpoch 117/1000 | Train Loss: 0.5293 | Val Loss: 0.5391\nEpoch 118/1000 | Train Loss: 0.5301 | Val Loss: 0.5487\nEpoch 119/1000 | Train Loss: 0.5285 | Val Loss: 0.5408\nEpoch 120/1000 | Train Loss: 0.5295 | Val Loss: 0.5423\nEpoch 121/1000 | Train Loss: 0.5280 | Val Loss: 0.5445\nEpoch 122/1000 | Train Loss: 0.5286 | Val Loss: 0.5365\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 123/1000 | Train Loss: 0.5316 | Val Loss: 0.5487\nEpoch 124/1000 | Train Loss: 0.5286 | Val Loss: 0.5467\nEpoch 125/1000 | Train Loss: 0.5290 | Val Loss: 0.5390\nEpoch 126/1000 | Train Loss: 0.5260 | Val Loss: 0.5427\nEpoch 127/1000 | Train Loss: 0.5306 | Val Loss: 0.5436\nEpoch 128/1000 | Train Loss: 0.5319 | Val Loss: 0.5619\nEpoch 129/1000 | Train Loss: 0.5286 | Val Loss: 0.5479\nEpoch 130/1000 | Train Loss: 0.5291 | Val Loss: 0.5417\nEpoch 131/1000 | Train Loss: 0.5271 | Val Loss: 0.5564\nEpoch 132/1000 | Train Loss: 0.5286 | Val Loss: 0.5336\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 133/1000 | Train Loss: 0.5300 | Val Loss: 0.5406\nEpoch 134/1000 | Train Loss: 0.5313 | Val Loss: 0.5498\nEpoch 135/1000 | Train Loss: 0.5292 | Val Loss: 0.5563\nEpoch 136/1000 | Train Loss: 0.5299 | Val Loss: 0.5462\nEpoch 137/1000 | Train Loss: 0.5276 | Val Loss: 0.5693\nEpoch 138/1000 | Train Loss: 0.5438 | Val Loss: 0.5664\nEpoch 139/1000 | Train Loss: 0.5607 | Val Loss: 0.5908\nEpoch 140/1000 | Train Loss: 0.5297 | Val Loss: 0.5503\nEpoch 141/1000 | Train Loss: 0.5748 | Val Loss: 0.5994\nEpoch 142/1000 | Train Loss: 0.5736 | Val Loss: 0.5811\nEpoch 143/1000 | Train Loss: 0.5773 | Val Loss: 0.6056\nEpoch 144/1000 | Train Loss: 0.5535 | Val Loss: 0.5731\nEpoch 145/1000 | Train Loss: 0.5494 | Val Loss: 0.5603\nEpoch 146/1000 | Train Loss: 0.5662 | Val Loss: 0.5736\nEpoch 147/1000 | Train Loss: 0.5515 | Val Loss: 0.5694\nEpoch 148/1000 | Train Loss: 0.5416 | Val Loss: 0.5622\nEpoch 149/1000 | Train Loss: 0.5555 | Val Loss: 0.5836\nEpoch 150/1000 | Train Loss: 0.5477 | Val Loss: 0.5591\nEpoch 151/1000 | Train Loss: 0.5434 | Val Loss: 0.5534\nEpoch 152/1000 | Train Loss: 0.5387 | Val Loss: 0.5565\nEpoch 153/1000 | Train Loss: 0.5465 | Val Loss: 0.5514\nEpoch 154/1000 | Train Loss: 0.5375 | Val Loss: 0.5480\nEpoch 155/1000 | Train Loss: 0.5335 | Val Loss: 0.5535\nEpoch 156/1000 | Train Loss: 0.5369 | Val Loss: 0.5503\nEpoch 157/1000 | Train Loss: 0.5346 | Val Loss: 0.5512\nEpoch 158/1000 | Train Loss: 0.5355 | Val Loss: 0.5437\nEpoch 159/1000 | Train Loss: 0.5351 | Val Loss: 0.5553\nEpoch 160/1000 | Train Loss: 0.5330 | Val Loss: 0.5471\nEpoch 161/1000 | Train Loss: 0.5339 | Val Loss: 0.5440\nEpoch 162/1000 | Train Loss: 0.5314 | Val Loss: 0.5554\nEpoch 163/1000 | Train Loss: 0.5322 | Val Loss: 0.5368\nEpoch 164/1000 | Train Loss: 0.5321 | Val Loss: 0.5474\nEpoch 165/1000 | Train Loss: 0.5303 | Val Loss: 0.5461\nEpoch 166/1000 | Train Loss: 0.5305 | Val Loss: 0.5484\nEpoch 167/1000 | Train Loss: 0.5304 | Val Loss: 0.5455\nEpoch 168/1000 | Train Loss: 0.5308 | Val Loss: 0.5571\nEpoch 169/1000 | Train Loss: 0.5302 | Val Loss: 0.5438\nEpoch 170/1000 | Train Loss: 0.5291 | Val Loss: 0.5500\nEpoch 171/1000 | Train Loss: 0.5289 | Val Loss: 0.5507\nEpoch 172/1000 | Train Loss: 0.5281 | Val Loss: 0.5564\nEpoch 173/1000 | Train Loss: 0.5287 | Val Loss: 0.5607\nEpoch 174/1000 | Train Loss: 0.5248 | Val Loss: 0.5304\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 175/1000 | Train Loss: 0.5272 | Val Loss: 0.5501\nEpoch 176/1000 | Train Loss: 0.5295 | Val Loss: 0.5592\nEpoch 177/1000 | Train Loss: 0.5269 | Val Loss: 0.5514\nEpoch 178/1000 | Train Loss: 0.5300 | Val Loss: 0.5417\nEpoch 179/1000 | Train Loss: 0.5299 | Val Loss: 0.5444\nEpoch 180/1000 | Train Loss: 0.5274 | Val Loss: 0.5512\nEpoch 181/1000 | Train Loss: 0.5267 | Val Loss: 0.5472\nEpoch 182/1000 | Train Loss: 0.5262 | Val Loss: 0.5345\nEpoch 183/1000 | Train Loss: 0.5276 | Val Loss: 0.5449\nEpoch 184/1000 | Train Loss: 0.5260 | Val Loss: 0.5375\nEpoch 185/1000 | Train Loss: 0.5243 | Val Loss: 0.5328\nEpoch 186/1000 | Train Loss: 0.5252 | Val Loss: 0.5280\nValidation loss improved. Saved model to /kaggle/working/linkpred_model_final.pt\nEpoch 187/1000 | Train Loss: 0.5255 | Val Loss: 0.5382\nEpoch 188/1000 | Train Loss: 0.5253 | Val Loss: 0.5440\nEpoch 189/1000 | Train Loss: 0.5252 | Val Loss: 0.5457\nEpoch 190/1000 | Train Loss: 0.5257 | Val Loss: 0.5565\nEpoch 191/1000 | Train Loss: 0.5264 | Val Loss: 0.5441\nEpoch 192/1000 | Train Loss: 0.5242 | Val Loss: 0.5567\nEpoch 193/1000 | Train Loss: 0.5277 | Val Loss: 0.5489\nEpoch 194/1000 | Train Loss: 0.5259 | Val Loss: 0.5448\nEpoch 195/1000 | Train Loss: 0.5253 | Val Loss: 0.5421\nEpoch 196/1000 | Train Loss: 0.5225 | Val Loss: 0.5482\nEpoch 197/1000 | Train Loss: 0.5258 | Val Loss: 0.5488\nEpoch 198/1000 | Train Loss: 0.5272 | Val Loss: 0.5475\nEpoch 199/1000 | Train Loss: 0.5243 | Val Loss: 0.5341\nEpoch 200/1000 | Train Loss: 0.5224 | Val Loss: 0.5448\nEpoch 201/1000 | Train Loss: 0.5219 | Val Loss: 0.5515\nEpoch 202/1000 | Train Loss: 0.5221 | Val Loss: 0.5414\nEpoch 203/1000 | Train Loss: 0.5223 | Val Loss: 0.5474\nEpoch 204/1000 | Train Loss: 0.5244 | Val Loss: 0.5538\nEpoch 205/1000 | Train Loss: 0.5255 | Val Loss: 0.5412\nEpoch 206/1000 | Train Loss: 0.5239 | Val Loss: 0.5337\nEpoch 207/1000 | Train Loss: 0.5245 | Val Loss: 0.5358\nEpoch 208/1000 | Train Loss: 0.5230 | Val Loss: 0.5479\nEpoch 209/1000 | Train Loss: 0.5231 | Val Loss: 0.5457\nEpoch 210/1000 | Train Loss: 0.5222 | Val Loss: 0.5498\nEpoch 211/1000 | Train Loss: 0.5257 | Val Loss: 0.5385\nEpoch 212/1000 | Train Loss: 0.5209 | Val Loss: 0.5470\nEpoch 213/1000 | Train Loss: 0.5228 | Val Loss: 0.5523\nEpoch 214/1000 | Train Loss: 0.5231 | Val Loss: 0.5419\nEpoch 215/1000 | Train Loss: 0.5213 | Val Loss: 0.5374\nEpoch 216/1000 | Train Loss: 0.5228 | Val Loss: 0.5521\nEpoch 217/1000 | Train Loss: 0.5224 | Val Loss: 0.5420\nEpoch 218/1000 | Train Loss: 0.5200 | Val Loss: 0.5349\nEpoch 219/1000 | Train Loss: 0.5234 | Val Loss: 0.5336\nEpoch 220/1000 | Train Loss: 0.5231 | Val Loss: 0.5370\nEpoch 221/1000 | Train Loss: 0.5176 | Val Loss: 0.5423\nEpoch 222/1000 | Train Loss: 0.5183 | Val Loss: 0.5461\nEpoch 223/1000 | Train Loss: 0.5180 | Val Loss: 0.5414\nEpoch 224/1000 | Train Loss: 0.5187 | Val Loss: 0.5429\nEpoch 225/1000 | Train Loss: 0.5168 | Val Loss: 0.5376\nEpoch 226/1000 | Train Loss: 0.5159 | Val Loss: 0.5379\nEpoch 227/1000 | Train Loss: 0.5129 | Val Loss: 0.5455\nEpoch 228/1000 | Train Loss: 0.5162 | Val Loss: 0.5383\nEpoch 229/1000 | Train Loss: 0.5152 | Val Loss: 0.5475\nEpoch 230/1000 | Train Loss: 0.5169 | Val Loss: 0.5343\nEpoch 231/1000 | Train Loss: 0.5165 | Val Loss: 0.5399\nEpoch 232/1000 | Train Loss: 0.5189 | Val Loss: 0.5415\nEpoch 233/1000 | Train Loss: 0.5148 | Val Loss: 0.5297\nEpoch 234/1000 | Train Loss: 0.5160 | Val Loss: 0.5363\nEpoch 235/1000 | Train Loss: 0.5167 | Val Loss: 0.5336\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2875912480.py:519: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(args.out_model_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 236/1000 | Train Loss: 0.5165 | Val Loss: 0.5379\nValidation loss did not improve for 50 epochs. Early stopping.\nLoading best model state from /kaggle/working/linkpred_model_final.pt\nGenerating final embeddings for training nodes using the best model...\nFinal training node embeddings shape: torch.Size([6217, 64])\nTraining complete.\nPerforming inference with test‐nodes isolated…\nFinal embeddings generated for all nodes. Shape: torch.Size([6545, 64])\nSaving final full embeddings to /kaggle/working/node_embeddings_final.pt\n\n--- Evaluating on 328 Test Nodes ---\ntorch.Size([6545, 64])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating test nodes: 100%|██████████| 328/328 [00:00<00:00, 5063.66it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Evaluation Summary ---\nEvaluated on 301 test nodes (nodes with actual outgoing links).\nAverage Hit Rate @10: 0.2159\nAverage Precision @10: 0.0272\nAverage Recall @10: 0.0485\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"title = 'Neural Tangent Kernel'\nabstract = 'This shows theoritical approximations'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:20:02.668557Z","iopub.execute_input":"2025-05-05T17:20:02.669228Z","iopub.status.idle":"2025-05-05T17:20:02.672356Z","shell.execute_reply.started":"2025-05-05T17:20:02.669204Z","shell.execute_reply":"2025-05-05T17:20:02.671700Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsbert = SentenceTransformer('all-MiniLM-L6-v2')\n\ndef convert_str_to_embeddding(txt):\n    max_len = 512\n    if len(txt.split()) > max_len:\n        txt = ' '.join(txt.split()[:max_len])\n    emb = sbert.encode(txt.strip(), convert_to_tensor=True, show_progress_bar=False)\n    return emb.to('cpu')\n\nemb = convert_str_to_embeddding(title+' '+abstract)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:23:31.756429Z","iopub.execute_input":"2025-05-05T17:23:31.756692Z","iopub.status.idle":"2025-05-05T17:23:35.407573Z","shell.execute_reply.started":"2025-05-05T17:23:31.756671Z","shell.execute_reply":"2025-05-05T17:23:35.406946Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nw = torch.load('/kaggle/input/text-embeddings/text_embeddings.pt')\nw.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:23:38.261435Z","iopub.execute_input":"2025-05-05T17:23:38.262113Z","iopub.status.idle":"2025-05-05T17:23:38.278531Z","shell.execute_reply.started":"2025-05-05T17:23:38.262083Z","shell.execute_reply":"2025-05-05T17:23:38.277973Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3787199675.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  w = torch.load('/kaggle/input/text-embeddings/text_embeddings.pt')\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"torch.Size([6545, 384])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"emb.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:23:40.539646Z","iopub.execute_input":"2025-05-05T17:23:40.540343Z","iopub.status.idle":"2025-05-05T17:23:40.545240Z","shell.execute_reply.started":"2025-05-05T17:23:40.540322Z","shell.execute_reply":"2025-05-05T17:23:40.544364Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"x_full = torch.cat([w, emb.unsqueeze(0)], dim=0)\nx_full.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:23:42.179934Z","iopub.execute_input":"2025-05-05T17:23:42.180556Z","iopub.status.idle":"2025-05-05T17:23:42.191156Z","shell.execute_reply.started":"2025-05-05T17:23:42.180525Z","shell.execute_reply":"2025-05-05T17:23:42.190380Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"torch.Size([6546, 384])"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import os\nimport networkx as nx\ndef load_full_graph_data(graph_path):\n    if not os.path.exists(graph_path):\n         raise FileNotFoundError(f\"Graph file not found: {graph_path}\")\n    Gnx = nx.read_graphml(graph_path)\n    print(f\"Full graph loaded: {Gnx.number_of_nodes()} nodes, {Gnx.number_of_edges()} edges.\")\n\n    nodes = list(Gnx.nodes())\n    mapping = {nid: i for i, nid in enumerate(nodes)}\n    inv_mapping = {i: nid for nid, i in mapping.items()}\n\n    edges = [[mapping[u], mapping[v]] for u, v in Gnx.edges() if u in mapping and v in mapping]\n    if not edges:\n        print(\"Warning: No edges found or mapped in the graph!\")\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    else:\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n    print(f\"Full edge_index created with shape: {edge_index.shape}\")\n    return Gnx, edge_index\n\nG, edge_index = load_full_graph_data('/kaggle/input/final-graph/final_citations_graph.graphml')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:25:46.356952Z","iopub.execute_input":"2025-05-05T17:25:46.357593Z","iopub.status.idle":"2025-05-05T17:25:46.830415Z","shell.execute_reply.started":"2025-05-05T17:25:46.357569Z","shell.execute_reply":"2025-05-05T17:25:46.829785Z"}},"outputs":[{"name":"stdout","text":"Full graph loaded: 6545 nodes, 28562 edges.\nFull edge_index created with shape: torch.Size([2, 28562])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:27:49.449906Z","iopub.execute_input":"2025-05-05T17:27:49.450557Z","iopub.status.idle":"2025-05-05T17:27:57.138961Z","shell.execute_reply.started":"2025-05-05T17:27:49.450537Z","shell.execute_reply":"2025-05-05T17:27:57.138117Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from torch_geometric.nn import GraphSAGE\n\nclass LinkPredictor(torch.nn.Module):\n    def __init__(self, in_dim=384, hidden=128, num_layers=2):\n        super().__init__()\n        self.sage = GraphSAGE(in_channels=in_dim, hidden_channels=hidden, num_layers=num_layers, out_channels=hidden) # Explicitly set out_channels\n        # No linear layer needed for dot product score\n\n    def forward(self, x, edge_index):\n         # Only encode nodes using GraphSAGE\n        h = self.sage(x, edge_index)\n        return h # Return node embeddings\n\n    def decode(self, h, edge_label_index):\n        # Decode links using dot product\n        return (h[edge_label_index[0]] * h[edge_label_index[1]]).sum(dim=1)\n        \nmodel = LinkPredictor(in_dim=x_full.size(1), hidden=64, num_layers=3).to('cpu')\nmodel.load_state_dict(torch.load('/kaggle/working/linkpred_model_final.pt', map_location='cpu'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:35:24.176748Z","iopub.execute_input":"2025-05-05T17:35:24.177041Z","iopub.status.idle":"2025-05-05T17:35:24.191630Z","shell.execute_reply.started":"2025-05-05T17:35:24.177020Z","shell.execute_reply":"2025-05-05T17:35:24.190849Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3942004862.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/linkpred_model_final.pt', map_location='cpu'))\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"full_node_emb = model(x_full, edge_index).cpu()\nfull_node_emb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:35:57.911599Z","iopub.execute_input":"2025-05-05T17:35:57.912183Z","iopub.status.idle":"2025-05-05T17:35:57.958369Z","shell.execute_reply.started":"2025-05-05T17:35:57.912156Z","shell.execute_reply":"2025-05-05T17:35:57.957642Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([6546, 64])"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"nodes = list(G.nodes())\nmapping = {nid: i for i, nid in enumerate(nodes)}\ninv_mapping = {i: nid for nid, i in mapping.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:41:06.542677Z","iopub.execute_input":"2025-05-05T17:41:06.542936Z","iopub.status.idle":"2025-05-05T17:41:06.548887Z","shell.execute_reply.started":"2025-05-05T17:41:06.542917Z","shell.execute_reply":"2025-05-05T17:41:06.548247Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"query_emb = full_node_emb[-1]\nscores = torch.matmul(full_node_emb, query_emb)\ntopk_scores, topk_indices_full = torch.topk(scores, k=10)\ntopk_indices_full","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:43:03.114736Z","iopub.execute_input":"2025-05-05T17:43:03.115244Z","iopub.status.idle":"2025-05-05T17:43:03.121347Z","shell.execute_reply.started":"2025-05-05T17:43:03.115222Z","shell.execute_reply":"2025-05-05T17:43:03.120594Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([5190,  869, 1869, 3191, 3307, 1602, 1981, 5452,  313, 3536])"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"title_map = build_title_map('/kaggle/input/papers/dataset_papers')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:43:15.364012Z","iopub.execute_input":"2025-05-05T17:43:15.364553Z","iopub.status.idle":"2025-05-05T17:44:37.788900Z","shell.execute_reply.started":"2025-05-05T17:43:15.364529Z","shell.execute_reply":"2025-05-05T17:44:37.788253Z"}},"outputs":[{"name":"stdout","text":"Total items in data_dir: 6545\n","output_type":"stream"},{"name":"stderr","text":"Building title map: 100%|██████████| 6545/6545 [01:22<00:00, 79.52it/s] ","output_type":"stream"},{"name":"stdout","text":"Found 6545 papers with titles.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"torch.save(title_map, 'title_map.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:57:25.869461Z","iopub.execute_input":"2025-05-05T17:57:25.869987Z","iopub.status.idle":"2025-05-05T17:57:25.880582Z","shell.execute_reply.started":"2025-05-05T17:57:25.869964Z","shell.execute_reply":"2025-05-05T17:57:25.880040Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"title_map1 = torch.load('title_map.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:57:46.061596Z","iopub.execute_input":"2025-05-05T17:57:46.062113Z","iopub.status.idle":"2025-05-05T17:57:46.070573Z","shell.execute_reply.started":"2025-05-05T17:57:46.062090Z","shell.execute_reply":"2025-05-05T17:57:46.069976Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3336012522.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  title_map1 = torch.load('title_map.pt')\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"title_map1 == title_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:57:57.137112Z","iopub.execute_input":"2025-05-05T17:57:57.137354Z","iopub.status.idle":"2025-05-05T17:57:57.143193Z","shell.execute_reply.started":"2025-05-05T17:57:57.137338Z","shell.execute_reply":"2025-05-05T17:57:57.142392Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"for idx in topk_indices_full.tolist():\n    print(title_map[inv_mapping[idx]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:46:01.757540Z","iopub.execute_input":"2025-05-05T17:46:01.758231Z","iopub.status.idle":"2025-05-05T17:46:01.762241Z","shell.execute_reply.started":"2025-05-05T17:46:01.758206Z","shell.execute_reply":"2025-05-05T17:46:01.761506Z"}},"outputs":[{"name":"stdout","text":"Approximate Inference Turns Deep Networks into Gaussian Processes\nBayesian GAN\nRandom Feature Expansions for Deep Gaussian Processes\nA Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods\nPractical Deep Learning with Bayesian Principles\nFast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam\nGlobal inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes\nMultiplicative Normalizing Flows for Variational Bayesian Neural Networks\nAccelerated Linearized Laplace Approximation for Bayesian Deep Learning\nLiberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}